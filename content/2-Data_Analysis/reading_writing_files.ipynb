{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b846b0",
   "metadata": {},
   "source": [
    "# Reading and Writing Files in Python\n",
    "\n",
    "A practical guide for Data Analysts\n",
    "\n",
    "**You'll learn:**\n",
    "- How to work with different file formats (TXT, CSV, Excel, JSON)\n",
    "- Basic Python file operations\n",
    "- Why and how to use Pandas for data files\n",
    "- Best practices for real-world scenarios\n",
    "\n",
    "**Why is this important?**\n",
    "As a Data Analyst, 90% of your work starts with loading data from files. You need to master this skill to be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c5f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f89c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries we'll use throughout this notebook\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "print(\"‚úì Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5e3a6",
   "metadata": {},
   "source": [
    "## 1. Understanding File Paths\n",
    "\n",
    "Before reading any file, you need to know WHERE it is.\n",
    "\n",
    "**Key concepts:**\n",
    "- **Current directory**: Where your Python program is running\n",
    "- **Relative path**: Path from current directory (`data/file.csv`)\n",
    "- **Absolute path**: Complete path (`C:/Users/you/data/file.csv`)\n",
    "\n",
    "**Best practice:** Always use `os.path.join()` for cross-platform compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de336a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are we now?\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìÅ Current directory: {current_dir}\")\n",
    "\n",
    "# Create a 'data' folder for our examples\n",
    "data_dir = \"data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(f\"‚úì Created '{data_dir}' folder\")\n",
    "else:\n",
    "    print(f\"‚úì '{data_dir}' folder exists\")\n",
    "\n",
    "# Build paths safely (works on Windows, Mac, Linux)\n",
    "csv_path = os.path.join(data_dir, \"sales.csv\")\n",
    "excel_path = os.path.join(data_dir, \"report.xlsx\")\n",
    "\n",
    "print(f\"\\nüìÑ Example paths:\")\n",
    "print(f\"  CSV: {csv_path}\")\n",
    "print(f\"  Excel: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c368d87",
   "metadata": {},
   "source": [
    "## 2. Text Files (.txt)\n",
    "\n",
    "The simplest file format - just plain text.\n",
    "\n",
    "**When to use:**\n",
    "- Log files\n",
    "- Simple notes\n",
    "- Configuration files\n",
    "- When you need basic text storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99003d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE a text file\n",
    "file_path = os.path.join(\"data\", \"notes.txt\")\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(\"Data Analysis Notes\\n\")\n",
    "    file.write(\"===================\\n\")\n",
    "    file.write(\"Always check your data for null values!\\n\")\n",
    "\n",
    "print(f\"‚úì Created: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ a text file - Line by line\n",
    "with open(file_path, 'r') as file:\n",
    "    print(\"=== File Contents ===\")\n",
    "    for line_num, line in enumerate(file, 1):\n",
    "        print(f\"{line_num}: {line.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c1804",
   "metadata": {},
   "source": [
    "## 3. CSV Files - The Data Analyst's Best Friend\n",
    "\n",
    "**CSV = Comma Separated Values**\n",
    "\n",
    "**Why CSV is important:**\n",
    "- ‚úì Universal format (works everywhere)\n",
    "- ‚úì Lightweight (small file size)\n",
    "- ‚úì Easy to share and version control\n",
    "- ‚úì Readable by Excel, Python, R, SQL...\n",
    "\n",
    "**Structure:**\n",
    "```\n",
    "Name,Age,Department,Salary\n",
    "Alice,25,IT,50000\n",
    "Bob,30,Sales,60000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a567ec",
   "metadata": {},
   "source": [
    "### Method 1: CSV with Python's csv module (basic)\n",
    "\n",
    "Good to know, but you'll rarely use this as a Data Analyst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7195a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# CREATE a CSV with Python's csv module\n",
    "csv_file = os.path.join(\"data\", \"employees.csv\")\n",
    "\n",
    "employees = [\n",
    "    [\"Name\", \"Age\", \"Department\", \"Salary\"],\n",
    "    [\"Alice\", 25, \"IT\", 50000],\n",
    "    [\"Bob\", 30, \"Sales\", 60000],\n",
    "    [\"Charlie\", 35, \"IT\", 55000],\n",
    "    [\"Diana\", 28, \"HR\", 65000],\n",
    "]\n",
    "\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(employees)\n",
    "\n",
    "print(f\"‚úì CSV created: {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00cf531",
   "metadata": {},
   "source": [
    "### Method 2: CSV with Pandas (recommended for Data Analysts)\n",
    "\n",
    "**This is what you'll use 99% of the time!**\n",
    "\n",
    "One line to read, instant analysis capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d8976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ CSV with Pandas - Simple and powerful\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(\"=== CSV Data as DataFrame ===\")\n",
    "print(df)\n",
    "print(f\"\\nüìä Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"üìã Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instant analysis!\n",
    "print(\"=== Quick Analysis ===\")\n",
    "print(f\"Average salary: ${df['Salary'].mean():,.2f}\")\n",
    "print(f\"Age range: {df['Age'].min()} - {df['Age'].max()}\")\n",
    "print(f\"\\nEmployees by department:\")\n",
    "print(df['Department'].value_counts())\n",
    "print(f\"\\nTop 2 salaries:\")\n",
    "print(df.nlargest(2, 'Salary')[['Name', 'Salary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed64e76",
   "metadata": {},
   "source": [
    "### Common CSV Reading Options\n",
    "\n",
    "As a Data Analyst, you'll need these options frequently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Only read specific columns\n",
    "df_partial = pd.read_csv(csv_file, usecols=['Name', 'Salary'])\n",
    "print(\"Only Name and Salary:\")\n",
    "print(df_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63167b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: CSV with semicolon separator (common in Europe)\n",
    "csv_euro = os.path.join(\"data\", \"employees_euro.csv\")\n",
    "df.to_csv(csv_euro, sep=';', index=False)\n",
    "\n",
    "df_euro = pd.read_csv(csv_euro, sep=';')\n",
    "print(\"CSV with ';' separator:\")\n",
    "print(df_euro.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Read only first N rows (useful for large files)\n",
    "df_sample = pd.read_csv(csv_file, nrows=2)\n",
    "print(\"Only first 2 rows:\")\n",
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbef90c",
   "metadata": {},
   "source": [
    "### Writing CSV Files\n",
    "\n",
    "Save your analysis results back to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a calculated column\n",
    "df['Salary_Bonus'] = df['Salary'] * 1.10  # 10% bonus\n",
    "\n",
    "# Save to new CSV\n",
    "output_file = os.path.join(\"data\", \"employees_with_bonus.csv\")\n",
    "df.to_csv(\n",
    "    output_file,\n",
    "    index=False,        # Don't save row numbers\n",
    "    sep=';',            # Use semicolon\n",
    "    float_format='%.2f' # 2 decimal places\n",
    ")\n",
    "\n",
    "print(f\"‚úì Saved to: {output_file}\")\n",
    "print(pd.read_csv(output_file, sep=';'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371f83d",
   "metadata": {},
   "source": [
    "## 4. Excel Files - For Business Reports\n",
    "\n",
    "**When to use Excel:**\n",
    "- Creating reports for non-technical people\n",
    "- Need multiple sheets\n",
    "- Want formatting and colors\n",
    "- Company standard is Excel\n",
    "\n",
    "**Note:** Install openpyxl first: `pip install openpyxl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d43920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if openpyxl is installed\n",
    "try:\n",
    "    import openpyxl\n",
    "    print(\"‚úì openpyxl is ready\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Install with: pip install openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39466066",
   "metadata": {},
   "source": [
    "### Reading Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b609b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE an Excel file first\n",
    "excel_file = os.path.join(\"data\", \"sales_report.xlsx\")\n",
    "\n",
    "df_sales = pd.DataFrame({\n",
    "    'Product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones'],\n",
    "    'Price': [999.99, 29.99, 79.99, 349.99, 149.99],\n",
    "    'Units_Sold': [45, 200, 150, 30, 85],\n",
    "    'Category': ['Electronics', 'Accessories', 'Accessories', 'Electronics', 'Accessories']\n",
    "})\n",
    "\n",
    "df_sales.to_excel(excel_file, index=False, sheet_name='Sales_Q1')\n",
    "print(f\"‚úì Excel created: {excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cded136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ Excel file\n",
    "df_from_excel = pd.read_excel(excel_file)\n",
    "\n",
    "print(\"=== Excel Data ===\")\n",
    "print(df_from_excel)\n",
    "print(f\"\\nüí∞ Total Revenue: ${(df_from_excel['Price'] * df_from_excel['Units_Sold']).sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd1361",
   "metadata": {},
   "source": [
    "### Working with Multiple Sheets\n",
    "\n",
    "Real-world Excel files often have multiple sheets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb92a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE Excel with multiple sheets\n",
    "excel_multi = os.path.join(\"data\", \"quarterly_report.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(excel_multi, engine='openpyxl') as writer:\n",
    "    # Sheet 1: All data\n",
    "    df_sales.to_excel(writer, sheet_name='All_Products', index=False)\n",
    "    \n",
    "    # Sheet 2: Electronics only\n",
    "    electronics = df_sales[df_sales['Category'] == 'Electronics']\n",
    "    electronics.to_excel(writer, sheet_name='Electronics', index=False)\n",
    "    \n",
    "    # Sheet 3: Summary\n",
    "    summary = df_sales.groupby('Category').agg({\n",
    "        'Price': 'mean',\n",
    "        'Units_Sold': 'sum'\n",
    "    }).round(2)\n",
    "    summary.to_excel(writer, sheet_name='Summary')\n",
    "\n",
    "print(f\"‚úì Multi-sheet Excel created: {excel_multi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4284cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ specific sheet\n",
    "df_electronics = pd.read_excel(excel_multi, sheet_name='Electronics')\n",
    "print(\"=== Electronics Sheet ===\")\n",
    "print(df_electronics)\n",
    "\n",
    "# READ all sheets at once\n",
    "all_sheets = pd.read_excel(excel_multi, sheet_name=None)\n",
    "print(f\"\\nüìÑ Available sheets: {list(all_sheets.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a677cf",
   "metadata": {},
   "source": [
    "## 5. JSON Files - For Structured Data\n",
    "\n",
    "**JSON = JavaScript Object Notation**\n",
    "\n",
    "**When to use:**\n",
    "- Data from APIs\n",
    "- Hierarchical/nested data\n",
    "- Configuration files\n",
    "- Modern data interchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b127cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE and SAVE JSON\n",
    "data = {\n",
    "    \"analyst\": \"John Doe\",\n",
    "    \"project\": \"Sales Analysis Q1 2024\",\n",
    "    \"metrics\": {\n",
    "        \"total_revenue\": 125000,\n",
    "        \"avg_order_value\": 450.50,\n",
    "        \"conversion_rate\": 0.045\n",
    "    },\n",
    "    \"top_products\": [\"Laptop\", \"Monitor\", \"Keyboard\"]\n",
    "}\n",
    "\n",
    "json_file = os.path.join(\"data\", \"analysis_results.json\")\n",
    "with open(json_file, \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(f\"‚úì JSON saved: {json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ JSON\n",
    "with open(json_file, \"r\") as f:\n",
    "    loaded_data = json.load(f)\n",
    "\n",
    "print(\"=== JSON Data ===\")\n",
    "print(f\"Analyst: {loaded_data['analyst']}\")\n",
    "print(f\"Revenue: ${loaded_data['metrics']['total_revenue']:,}\")\n",
    "print(f\"Top Products: {', '.join(loaded_data['top_products'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e861ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON to DataFrame (when data is tabular)\n",
    "employees_json = [\n",
    "    {\"name\": \"Alice\", \"age\": 25, \"dept\": \"IT\", \"salary\": 50000},\n",
    "    {\"name\": \"Bob\", \"age\": 30, \"dept\": \"Sales\", \"salary\": 60000},\n",
    "    {\"name\": \"Charlie\", \"age\": 35, \"dept\": \"IT\", \"salary\": 55000}\n",
    "]\n",
    "\n",
    "df_from_json = pd.DataFrame(employees_json)\n",
    "print(\"=== JSON ‚Üí DataFrame ===\")\n",
    "print(df_from_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3151d5",
   "metadata": {},
   "source": [
    "## 6. Working with ZIP Files\n",
    "\n",
    "Often you'll receive compressed data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76de2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE a ZIP with multiple files\n",
    "zip_path = os.path.join(\"data\", \"data_archive.zip\")\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "    zipf.write(csv_file, arcname='employees.csv')\n",
    "    zipf.write(json_file, arcname='results.json')\n",
    "\n",
    "print(f\"‚úì ZIP created: {zip_path}\")\n",
    "\n",
    "# List contents\n",
    "with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
    "    print(\"\\nüì¶ Files in ZIP:\")\n",
    "    for name in zipf.namelist():\n",
    "        print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ CSV directly from ZIP (no need to extract!)\n",
    "with zipfile.ZipFile(zip_path) as z:\n",
    "    with z.open('employees.csv') as f:\n",
    "        df_from_zip = pd.read_csv(f)\n",
    "\n",
    "print(\"=== CSV from ZIP ===\")\n",
    "print(df_from_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa52550",
   "metadata": {},
   "source": [
    "## 7. Encoding Issues (Important!)\n",
    "\n",
    "**Common problem:** Opening a file and seeing weird characters like `Espa√É¬±a` instead of `Espa√±a`.\n",
    "\n",
    "**Solution:** Always specify encoding='utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3531c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE CSV with special characters\n",
    "df_cities = pd.DataFrame({\n",
    "    'City': ['Madrid', 'Barcelona', 'M√°laga', 'A Coru√±a'],\n",
    "    'Country': ['Spain', 'Spain', 'Spain', 'Spain'],\n",
    "    'Population': [3223000, 1620000, 574000, 246000]\n",
    "})\n",
    "\n",
    "csv_encoded = os.path.join(\"data\", \"cities.csv\")\n",
    "df_cities.to_csv(csv_encoded, index=False, encoding='utf-8')\n",
    "\n",
    "# READ with correct encoding\n",
    "df_read = pd.read_csv(csv_encoded, encoding='utf-8')\n",
    "print(\"=== Cities (UTF-8) ===\")\n",
    "print(df_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f81c12",
   "metadata": {},
   "source": [
    "## 8. Best Practices for Data Analysts\n",
    "\n",
    "### File Organization\n",
    "```\n",
    "project/\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/          # Original files (DON'T MODIFY!)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ processed/    # Cleaned data\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ results/      # Analysis outputs\n",
    "‚îú‚îÄ‚îÄ notebooks/        # Your analysis notebooks\n",
    "‚îî‚îÄ‚îÄ reports/          # Final reports\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170640e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE recommended folder structure\n",
    "folders = ['data/raw', 'data/processed', 'data/results', 'reports']\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "print(\"‚úì Project structure created:\")\n",
    "for folder in folders:\n",
    "    print(f\"  üìÅ {folder}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76272318",
   "metadata": {},
   "source": [
    "### Always Verify Your Data After Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95961266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS do this after reading a file\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(\"=== Data Verification ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nBasic stats:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b2895",
   "metadata": {},
   "source": [
    "### Error Handling (Production Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047538c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_safely(file_path):\n",
    "    \"\"\"\n",
    "    Load CSV with proper error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"‚ùå File not found: {file_path}\")\n",
    "            return None\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"‚úì Loaded {len(df)} rows from {file_path}\")\n",
    "        return df\n",
    "        \n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"‚ùå File is empty: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test it\n",
    "df_safe = load_data_safely(csv_file)\n",
    "if df_safe is not None:\n",
    "    print(df_safe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba1224",
   "metadata": {},
   "source": [
    "## 9. Quick Reference Cheat Sheet\n",
    "\n",
    "```python\n",
    "# READ FILES\n",
    "df = pd.read_csv('file.csv')                    # CSV\n",
    "df = pd.read_csv('file.csv', sep=';')          # CSV with semicolon\n",
    "df = pd.read_excel('file.xlsx')                # Excel\n",
    "df = pd.read_excel('file.xlsx', sheet_name='Sheet1')  # Specific sheet\n",
    "df = pd.read_json('file.json')                 # JSON\n",
    "\n",
    "# WRITE FILES\n",
    "df.to_csv('output.csv', index=False)           # CSV\n",
    "df.to_excel('output.xlsx', index=False)        # Excel\n",
    "df.to_json('output.json')                      # JSON\n",
    "\n",
    "# COMMON OPTIONS\n",
    "encoding='utf-8'          # Character encoding\n",
    "sep=';'                   # Separator\n",
    "usecols=['A', 'B']       # Only certain columns\n",
    "nrows=100                 # Only first N rows\n",
    "sheet_name='Sales'        # Excel sheet name\n",
    "\n",
    "# FILE OPERATIONS\n",
    "os.getcwd()               # Current directory\n",
    "os.listdir('folder')      # List files\n",
    "os.path.exists('file')    # Check if exists\n",
    "os.path.join('a', 'b')    # Join paths safely\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06417461",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "**What you learned:**\n",
    "- ‚úì File paths and organization\n",
    "- ‚úì Reading/writing TXT, CSV, Excel, JSON\n",
    "- ‚úì Why Pandas is essential for data analysts\n",
    "- ‚úì Encoding issues and solutions\n",
    "- ‚úì Best practices for real projects\n",
    "\n",
    "**Key takeaways:**\n",
    "1. **Always use Pandas** for data files (CSV, Excel)\n",
    "2. **Always specify encoding='utf-8'**\n",
    "3. **Verify data** after loading (shape, head, dtypes, nulls)\n",
    "4. **Organize your files** (raw/processed/results)\n",
    "5. **Use relative paths** with `os.path.join()`\n",
    "\n",
    "**Next steps:**\n",
    "- Practice with real datasets (Kaggle, data.gov)\n",
    "- Learn Pandas DataFrame operations in depth\n",
    "- Master data cleaning and transformation\n",
    "- Start doing exploratory data analysis (EDA)\n",
    "\n",
    "**Resources:**\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [Pandas I/O Tools](https://pandas.pydata.org/docs/user_guide/io.html)\n",
    "- [Real Python - File I/O](https://realpython.com/read-write-files-python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
