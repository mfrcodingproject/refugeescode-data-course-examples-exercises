{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2db4e8bc",
   "metadata": {},
   "source": [
    "# Creating a Real Data Analysis Script\n",
    "\n",
    "Now that you've learned NumPy, Pandas, and data visualization, let's put it all together and create a **real, reusable data analysis script** that you can run from the command line or share with others.\n",
    "\n",
    "This is how professional data analysts work in real projects!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f6602",
   "metadata": {},
   "source": [
    "## Why Create Scripts Instead of Just Notebooks?\n",
    "\n",
    "### Advantages of Python Scripts:\n",
    "1. **Reusability**: Run the same analysis on different datasets\n",
    "2. **Automation**: Schedule scripts to run automatically\n",
    "3. **Sharing**: Easy to share with colleagues who don't use Jupyter\n",
    "4. **Version Control**: Better for Git and collaboration\n",
    "5. **Production Ready**: Can be integrated into larger systems\n",
    "6. **Command Line Arguments**: Make scripts flexible with parameters\n",
    "\n",
    "### When to Use Scripts vs Notebooks:\n",
    "- **Notebooks**: Exploration, learning, presenting results\n",
    "- **Scripts**: Automation, production, repeated analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485062b",
   "metadata": {},
   "source": [
    "## Project: Sales Data Analysis Script\n",
    "\n",
    "We'll create a complete data analysis script that:\n",
    "1. Loads data from a CSV file\n",
    "2. Cleans and processes the data\n",
    "3. Performs statistical analysis\n",
    "4. Generates visualizations\n",
    "5. Exports results to files\n",
    "6. Accepts command-line arguments\n",
    "\n",
    "This mimics real-world data analysis workflows!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24beec52",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Sample Data\n",
    "\n",
    "First, let's create sample sales data to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4685ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generate sample sales data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create dates for 6 months\n",
    "start_date = datetime(2024, 1, 1)\n",
    "dates = [start_date + timedelta(days=x) for x in range(180)]\n",
    "\n",
    "# Create sample data\n",
    "n_records = 500\n",
    "data = {\n",
    "    'date': np.random.choice(dates, n_records),\n",
    "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard'], n_records),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_records),\n",
    "    'salesperson': np.random.choice(['Alice', 'Bob', 'Charlie', 'Diana', 'Edward'], n_records),\n",
    "    'quantity': np.random.randint(1, 10, n_records),\n",
    "    'unit_price': np.random.choice([299, 599, 799, 999, 1299], n_records)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['total_sales'] = df['quantity'] * df['unit_price']\n",
    "\n",
    "# Add some missing values to make it realistic\n",
    "df.loc[np.random.choice(df.index, 10), 'quantity'] = np.nan\n",
    "df.loc[np.random.choice(df.index, 5), 'region'] = np.nan\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('sales_data.csv', index=False)\n",
    "print(\"Sample data created: sales_data.csv\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2ab417",
   "metadata": {},
   "source": [
    "## Step 2: Create the Analysis Script\n",
    "\n",
    "Now let's create a complete Python script that analyzes this data. We'll write it in a code cell first, then save it as a `.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the complete analysis script\n",
    "# We'll save this as 'sales_analysis.py'\n",
    "\n",
    "script_content = '''\n",
    "\"\"\"\n",
    "Sales Data Analysis Script\n",
    "--------------------------\n",
    "Analyzes sales data and generates reports and visualizations.\n",
    "\n",
    "Usage:\n",
    "    python sales_analysis.py sales_data.csv\n",
    "    python sales_analysis.py sales_data.csv --output-dir results\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import argparse\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load sales data from CSV file.\"\"\"\n",
    "    print(f\"Loading data from {filepath}...\")\n",
    "    df = pd.read_csv(filepath, parse_dates=['date'])\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Clean and prepare data for analysis.\"\"\"\n",
    "    print(\"\\\\nCleaning data...\")\n",
    "    \n",
    "    # Store original count\n",
    "    original_count = len(df)\n",
    "    \n",
    "    # Handle missing values\n",
    "    df = df.dropna(subset=['quantity', 'unit_price'])\n",
    "    df['region'] = df['region'].fillna('Unknown')\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Recalculate total_sales to ensure consistency\n",
    "    df['total_sales'] = df['quantity'] * df['unit_price']\n",
    "    \n",
    "    # Add derived columns\n",
    "    df['month'] = df['date'].dt.to_period('M')\n",
    "    df['day_of_week'] = df['date'].dt.day_name()\n",
    "    \n",
    "    removed = original_count - len(df)\n",
    "    print(f\"Removed {removed} invalid records\")\n",
    "    print(f\"Clean dataset: {len(df)} records\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def analyze_data(df):\n",
    "    \"\"\"Perform statistical analysis on the data.\"\"\"\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"SALES ANALYSIS REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(\"\\\\n1. OVERALL STATISTICS\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Total Revenue: ${df['total_sales'].sum():,.2f}\")\n",
    "    print(f\"Average Order Value: ${df['total_sales'].mean():,.2f}\")\n",
    "    print(f\"Total Units Sold: {df['quantity'].sum():,.0f}\")\n",
    "    print(f\"Number of Transactions: {len(df)}\")\n",
    "    \n",
    "    # Product analysis\n",
    "    print(\"\\\\n2. PRODUCT PERFORMANCE\")\n",
    "    print(\"-\" * 50)\n",
    "    product_stats = df.groupby('product').agg({\n",
    "        'total_sales': 'sum',\n",
    "        'quantity': 'sum'\n",
    "    }).sort_values('total_sales', ascending=False)\n",
    "    print(product_stats)\n",
    "    \n",
    "    # Regional analysis\n",
    "    print(\"\\\\n3. REGIONAL PERFORMANCE\")\n",
    "    print(\"-\" * 50)\n",
    "    region_stats = df.groupby('region').agg({\n",
    "        'total_sales': ['sum', 'mean', 'count']\n",
    "    }).round(2)\n",
    "    print(region_stats)\n",
    "    \n",
    "    # Salesperson performance\n",
    "    print(\"\\\\n4. SALESPERSON PERFORMANCE\")\n",
    "    print(\"-\" * 50)\n",
    "    sales_by_person = df.groupby('salesperson')['total_sales'].sum().sort_values(ascending=False)\n",
    "    print(sales_by_person)\n",
    "    \n",
    "    # Monthly trends\n",
    "    print(\"\\\\n5. MONTHLY TRENDS\")\n",
    "    print(\"-\" * 50)\n",
    "    monthly_sales = df.groupby('month')['total_sales'].sum()\n",
    "    print(monthly_sales)\n",
    "    \n",
    "    return {\n",
    "        'product_stats': product_stats,\n",
    "        'region_stats': region_stats,\n",
    "        'sales_by_person': sales_by_person,\n",
    "        'monthly_sales': monthly_sales\n",
    "    }\n",
    "\n",
    "\n",
    "def create_visualizations(df, stats, output_dir='outputs'):\n",
    "    \"\"\"Create and save visualizations.\"\"\"\n",
    "    print(f\"\\\\nCreating visualizations in '{output_dir}' directory...\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Sales by Product\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    stats['product_stats']['total_sales'].plot(kind='bar', color='skyblue')\n",
    "    plt.title('Total Sales by Product', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Product')\n",
    "    plt.ylabel('Total Sales ($)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/sales_by_product.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Sales by Region\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    region_sales = df.groupby('region')['total_sales'].sum()\n",
    "    plt.pie(region_sales, labels=region_sales.index, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Sales Distribution by Region', fontsize=16, fontweight='bold')\n",
    "    plt.savefig(f'{output_dir}/sales_by_region.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Monthly Sales Trend\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    monthly_data = df.groupby('month')['total_sales'].sum()\n",
    "    monthly_data.plot(kind='line', marker='o', linewidth=2, markersize=8)\n",
    "    plt.title('Monthly Sales Trend', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Total Sales ($)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/monthly_trend.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Salesperson Performance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    stats['sales_by_person'].plot(kind='barh', color='coral')\n",
    "    plt.title('Sales Performance by Salesperson', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Total Sales ($)')\n",
    "    plt.ylabel('Salesperson')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/salesperson_performance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Heatmap: Product vs Region\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    pivot_table = df.pivot_table(values='total_sales', index='product', \n",
    "                                  columns='region', aggfunc='sum', fill_value=0)\n",
    "    sns.heatmap(pivot_table, annot=True, fmt='.0f', cmap='YlOrRd', cbar_kws={'label': 'Total Sales ($)'})\n",
    "    plt.title('Sales Heatmap: Product vs Region', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/product_region_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Saved 5 visualizations to '{output_dir}' directory\")\n",
    "\n",
    "\n",
    "def export_results(df, stats, output_dir='outputs'):\n",
    "    \"\"\"Export analysis results to CSV files.\"\"\"\n",
    "    print(f\"\\\\nExporting results to '{output_dir}' directory...\")\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Export summary statistics\n",
    "    stats['product_stats'].to_csv(f'{output_dir}/product_summary.csv')\n",
    "    stats['sales_by_person'].to_csv(f'{output_dir}/salesperson_summary.csv')\n",
    "    stats['monthly_sales'].to_csv(f'{output_dir}/monthly_summary.csv')\n",
    "    \n",
    "    # Export cleaned data\n",
    "    df.to_csv(f'{output_dir}/cleaned_data.csv', index=False)\n",
    "    \n",
    "    print(f\"✓ Exported 4 CSV files to '{output_dir}' directory\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the analysis.\"\"\"\n",
    "    # Parse command-line arguments\n",
    "    parser = argparse.ArgumentParser(description='Analyze sales data and generate reports')\n",
    "    parser.add_argument('input_file', help='Path to input CSV file')\n",
    "    parser.add_argument('--output-dir', default='outputs', help='Output directory for results')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Run analysis pipeline\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"SALES DATA ANALYSIS SCRIPT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load data\n",
    "    df = load_data(args.input_file)\n",
    "    \n",
    "    # Clean data\n",
    "    df = clean_data(df)\n",
    "    \n",
    "    # Analyze data\n",
    "    stats = analyze_data(df)\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_visualizations(df, stats, args.output_dir)\n",
    "    \n",
    "    # Export results\n",
    "    export_results(df, stats, args.output_dir)\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\\\nAll results saved to: {args.output_dir}/\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Save the script to a file\n",
    "with open('sales_analysis.py', 'w') as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "print(\"✓ Created sales_analysis.py\")\n",
    "print(\"\\nYou can now run this script from the command line!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5738e02c",
   "metadata": {},
   "source": [
    "## Step 3: Run the Script\n",
    "\n",
    "Now let's run our script! There are several ways to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the script from within Jupyter\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Method 1: Run with default output directory\n",
    "result = subprocess.run([sys.executable, 'sales_analysis.py', 'sales_data.csv'], \n",
    "                       capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c271b53",
   "metadata": {},
   "source": [
    "## Running from Command Line\n",
    "\n",
    "You can also run this script directly from your terminal:\n",
    "\n",
    "```bash\n",
    "# Basic usage\n",
    "python sales_analysis.py sales_data.csv\n",
    "\n",
    "# Specify custom output directory\n",
    "python sales_analysis.py sales_data.csv --output-dir my_results\n",
    "\n",
    "# Get help\n",
    "python sales_analysis.py --help\n",
    "```\n",
    "\n",
    "This is how data analysts share and run analysis scripts in real projects!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ed9b1",
   "metadata": {},
   "source": [
    "## Step 4: View the Results\n",
    "\n",
    "Let's check what our script generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e61e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# List all generated files\n",
    "print(\"Generated files in 'outputs' directory:\")\n",
    "print(\"-\" * 50)\n",
    "for file in os.listdir('outputs'):\n",
    "    print(f\"  ✓ {file}\")\n",
    "\n",
    "# Display one of the visualizations\n",
    "print(\"\\nSample visualization:\")\n",
    "display(Image('outputs/sales_by_product.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the exported summary data\n",
    "print(\"Product Summary:\")\n",
    "product_summary = pd.read_csv('outputs/product_summary.csv')\n",
    "print(product_summary)\n",
    "\n",
    "print(\"\\n\\nSalesperson Summary:\")\n",
    "salesperson_summary = pd.read_csv('outputs/salesperson_summary.csv')\n",
    "print(salesperson_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2592c8",
   "metadata": {},
   "source": [
    "## Understanding the Script Structure\n",
    "\n",
    "Let's break down the key components of our analysis script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key components of a data analysis script:\n",
    "\n",
    "print(\"\"\"\n",
    "1. IMPORTS\n",
    "   - Import all necessary libraries at the top\n",
    "   - pandas, numpy, matplotlib, etc.\n",
    "\n",
    "2. CONFIGURATION\n",
    "   - Set visualization styles\n",
    "   - Define constants and parameters\n",
    "\n",
    "3. FUNCTIONS\n",
    "   - load_data(): Load and parse data\n",
    "   - clean_data(): Handle missing values, outliers\n",
    "   - analyze_data(): Perform calculations and statistics\n",
    "   - create_visualizations(): Generate charts and graphs\n",
    "   - export_results(): Save outputs to files\n",
    "\n",
    "4. COMMAND-LINE ARGUMENTS\n",
    "   - argparse module for flexible inputs\n",
    "   - Makes script reusable with different datasets\n",
    "\n",
    "5. MAIN FUNCTION\n",
    "   - Orchestrates the entire workflow\n",
    "   - Calls functions in the right order\n",
    "   - Handles errors gracefully\n",
    "\n",
    "6. __name__ == \"__main__\"\n",
    "   - Allows script to be imported or run directly\n",
    "   - Professional Python practice\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee003e3",
   "metadata": {},
   "source": [
    "## Making Scripts More Flexible\n",
    "\n",
    "Let's enhance our script with more command-line options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dfc1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of enhanced argument parser\n",
    "enhanced_parser = '''\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Analyze sales data and generate reports',\n",
    "    formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "    epilog=\"\"\"\n",
    "Examples:\n",
    "  python sales_analysis.py data.csv\n",
    "  python sales_analysis.py data.csv --output-dir results\n",
    "  python sales_analysis.py data.csv --no-plots\n",
    "  python sales_analysis.py data.csv --min-sales 1000\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Required arguments\n",
    "parser.add_argument('input_file', help='Path to input CSV file')\n",
    "\n",
    "# Optional arguments\n",
    "parser.add_argument('--output-dir', default='outputs', \n",
    "                   help='Output directory (default: outputs)')\n",
    "parser.add_argument('--no-plots', action='store_true',\n",
    "                   help='Skip generating visualizations')\n",
    "parser.add_argument('--min-sales', type=float, default=0,\n",
    "                   help='Filter sales below this amount')\n",
    "parser.add_argument('--export-format', choices=['csv', 'excel'], default='csv',\n",
    "                   help='Export format for results')\n",
    "'''\n",
    "\n",
    "print(\"Enhanced argument parser:\")\n",
    "print(enhanced_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9826476",
   "metadata": {},
   "source": [
    "## Best Practices for Data Analysis Scripts\n",
    "\n",
    "### 1. Code Organization\n",
    "- Use functions for modularity\n",
    "- Add docstrings to explain what each function does\n",
    "- Keep functions focused on one task\n",
    "\n",
    "### 2. Error Handling\n",
    "- Check if files exist before loading\n",
    "- Handle missing or invalid data gracefully\n",
    "- Provide clear error messages\n",
    "\n",
    "### 3. Documentation\n",
    "- Add comments to explain complex logic\n",
    "- Include usage examples in the docstring\n",
    "- Create a README file for your project\n",
    "\n",
    "### 4. Output Management\n",
    "- Create output directories automatically\n",
    "- Use timestamps in filenames to avoid overwriting\n",
    "- Save both data and visualizations\n",
    "\n",
    "### 5. Reproducibility\n",
    "- Set random seeds for consistent results\n",
    "- Document dependencies (requirements.txt)\n",
    "- Include sample data for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aa79a2",
   "metadata": {},
   "source": [
    "## Creating a requirements.txt File\n",
    "\n",
    "For sharing your script with others, create a requirements.txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create requirements.txt\n",
    "requirements = \"\"\"pandas>=2.0.0\n",
    "numpy>=1.24.0\n",
    "matplotlib>=3.7.0\n",
    "seaborn>=0.12.0\n",
    "\"\"\"\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(\"✓ Created requirements.txt\")\n",
    "print(\"\\nOthers can install dependencies with:\")\n",
    "print(\"  pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88efd8dc",
   "metadata": {},
   "source": [
    "## Exercise: Customize the Script\n",
    "\n",
    "Try modifying the script to add these features:\n",
    "\n",
    "### Easy:\n",
    "1. Add a new visualization (e.g., sales by day of week)\n",
    "2. Calculate and print the top 3 products\n",
    "3. Add a filter to analyze only a specific region\n",
    "\n",
    "### Medium:\n",
    "4. Add a `--start-date` and `--end-date` argument to analyze a date range\n",
    "5. Create a summary text file with all statistics\n",
    "6. Add exception handling for missing files\n",
    "\n",
    "### Advanced:\n",
    "7. Add a `--format` option to export results as Excel instead of CSV\n",
    "8. Create an interactive HTML dashboard using Plotly\n",
    "9. Add email functionality to send results automatically\n",
    "10. Optimize the script for large datasets (millions of rows)\n",
    "\n",
    "**Hint**: Start with copying `sales_analysis.py` to a new file and making small changes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc1595",
   "metadata": {},
   "source": [
    "## Real-World Applications\n",
    "\n",
    "This type of script is used in real data analytics projects for:\n",
    "\n",
    "1. **Automated Reporting**: Run daily/weekly reports automatically\n",
    "2. **Data Pipelines**: Part of ETL (Extract, Transform, Load) processes\n",
    "3. **Batch Processing**: Analyze multiple files at once\n",
    "4. **Production Systems**: Integrate with business applications\n",
    "5. **Collaboration**: Share analysis workflows with team members\n",
    "6. **Scheduling**: Use with cron (Linux) or Task Scheduler (Windows)\n",
    "\n",
    "### Example Workflow:\n",
    "```bash\n",
    "# Monday morning: analyze last week's data\n",
    "python sales_analysis.py weekly_sales.csv --output-dir reports/week_23\n",
    "\n",
    "# Generate monthly report\n",
    "python sales_analysis.py monthly_sales.csv --output-dir reports/january_2024\n",
    "\n",
    "# Batch process multiple regions\n",
    "for region in north south east west; do\n",
    "    python sales_analysis.py data_${region}.csv --output-dir reports/${region}\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02853a0a",
   "metadata": {},
   "source": [
    "## From Notebook to Script: Conversion Tips\n",
    "\n",
    "### When to Convert:\n",
    "- ✅ Analysis is working well in notebook\n",
    "- ✅ Need to run analysis repeatedly\n",
    "- ✅ Want to share with non-technical users\n",
    "- ✅ Need to automate the process\n",
    "\n",
    "### Conversion Steps:\n",
    "1. **Extract code from notebooks**: Copy working cells\n",
    "2. **Organize into functions**: Group related operations\n",
    "3. **Add parameters**: Make hardcoded values configurable\n",
    "4. **Add error handling**: Make script robust\n",
    "5. **Test thoroughly**: Run with different inputs\n",
    "6. **Document**: Add docstrings and comments\n",
    "\n",
    "### Tools to Help:\n",
    "- `nbconvert`: Convert notebooks to Python scripts\n",
    "- `papermill`: Run notebooks with parameters\n",
    "- `jupytext`: Sync notebooks and Python files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dba2eb8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned to:\n",
    "- ✅ Create a complete data analysis script\n",
    "- ✅ Use command-line arguments for flexibility\n",
    "- ✅ Structure code with functions and modules\n",
    "- ✅ Generate and save visualizations programmatically\n",
    "- ✅ Export results in multiple formats\n",
    "- ✅ Share reusable analysis workflows\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Scripts are reusable**: Write once, run many times\n",
    "2. **Automation saves time**: Let the computer do repetitive work\n",
    "3. **Professional workflow**: This is how real data analysts work\n",
    "4. **Shareable**: Easy to collaborate with team members\n",
    "5. **Integration ready**: Can be part of larger systems\n",
    "\n",
    "### Next Steps:\n",
    "- Practice creating scripts for different types of analysis\n",
    "- Learn about scheduling scripts to run automatically\n",
    "- Explore building web dashboards with Streamlit or Dash\n",
    "- Study data engineering and pipeline tools\n",
    "\n",
    "**Remember**: Start with notebooks for exploration, then convert to scripts for production!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
