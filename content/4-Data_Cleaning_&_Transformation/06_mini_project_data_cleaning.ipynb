{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab40a1a8",
   "metadata": {},
   "source": [
    "# üßπ Mini-Project: HR Data Cleaning & Transformation\n",
    "\n",
    "**Module 4: Data Cleaning & Transformation**\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Congratulations! You've been hired as a Data Analyst at a growing tech company. Your first task is to clean and prepare the HR department's employee dataset for analysis.\n",
    "\n",
    "The HR team has been maintaining employee records in a spreadsheet for years, and the data has become quite messy. Before the leadership team can make data-driven decisions about workforce planning, compensation analysis, and retention strategies, the data needs to be cleaned and transformed.\n",
    "\n",
    "### Your Mission\n",
    "\n",
    "Clean and transform the raw HR dataset so it can be used for:\n",
    "1. **Salary Analysis** - Fair compensation benchmarking across departments\n",
    "2. **Retention Analysis** - Understanding employee tenure and turnover\n",
    "3. **Performance Insights** - Correlating performance with other factors\n",
    "4. **Workforce Demographics** - Age distribution, education levels, remote work patterns\n",
    "\n",
    "### Skills You'll Practice\n",
    "- ‚úÖ Handling missing values\n",
    "- ‚úÖ Detecting and treating outliers\n",
    "- ‚úÖ Type conversion (strings to numbers, dates)\n",
    "- ‚úÖ Text cleaning and standardization\n",
    "- ‚úÖ Date/time manipulation\n",
    "- ‚úÖ Feature engineering\n",
    "- ‚úÖ Data validation and quality checks\n",
    "- ‚úÖ Documenting your decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e58143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 60)\n",
    "\n",
    "print(\"‚úì Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da56bc",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Data Loading & Initial Assessment\n",
    "\n",
    "### 1.1 Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw HR data\n",
    "df = pd.read_csv('data/raw_hr_data.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"\\nColumn Names:\\n{df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9dbc2",
   "metadata": {},
   "source": [
    "### 1.2 Initial Data Quality Assessment\n",
    "\n",
    "Before cleaning, we need to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c57e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and missing values\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "quality_report = pd.DataFrame({\n",
    "    'dtype': df.dtypes,\n",
    "    'non_null': df.count(),\n",
    "    'null_count': df.isnull().sum(),\n",
    "    'null_pct': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "    'unique': df.nunique(),\n",
    "    'sample_value': df.iloc[0]\n",
    "})\n",
    "\n",
    "print(quality_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d87b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at unique values for categorical-looking columns\n",
    "categorical_cols = ['department', 'education', 'is_remote', 'performance_rating']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"UNIQUE VALUES IN KEY COLUMNS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec4516c",
   "metadata": {},
   "source": [
    "---\n",
    "## üìã TASK 1: Document the Data Issues (15 minutes)\n",
    "\n",
    "Before cleaning, **document all the issues you find**. This is a critical skill for communicating with stakeholders.\n",
    "\n",
    "Fill in the table below after examining the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a7a13",
   "metadata": {},
   "source": [
    "### Data Issues Log\n",
    "\n",
    "| Column | Issue Type | Description | Proposed Solution |\n",
    "|--------|------------|-------------|-------------------|\n",
    "| employee_id | Missing | 1 row has missing ID | ? |\n",
    "| full_name | ? | ? | ? |\n",
    "| hire_date | ? | ? | ? |\n",
    "| birth_date | ? | ? | ? |\n",
    "| salary | ? | ? | ? |\n",
    "| email | ? | ? | ? |\n",
    "| phone | ? | ? | ? |\n",
    "| education | ? | ? | ? |\n",
    "| performance_rating | ? | ? | ? |\n",
    "| is_remote | ? | ? | ? |\n",
    "\n",
    "**Your Documentation Notes:**\n",
    "(Write your observations here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3319db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to explore the data and find issues\n",
    "# Hint: Look at unique values, check for patterns, identify inconsistencies\n",
    "\n",
    "# Example: Check salary column\n",
    "print(\"Sample salary values:\")\n",
    "print(df['salary'].head(20).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a58bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check date columns\n",
    "print(\"Sample hire_date values:\")\n",
    "print(df['hire_date'].unique()[:15])\n",
    "\n",
    "print(\"\\nSample birth_date values:\")\n",
    "print(df['birth_date'].unique()[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fed8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check phone formats\n",
    "print(\"Sample phone values:\")\n",
    "print(df['phone'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8e870",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Data Cleaning\n",
    "\n",
    "Now let's clean each column systematically.\n",
    "\n",
    "### üìã TASK 2: Clean the `full_name` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e157402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a working copy\n",
    "df_clean = df.copy()\n",
    "\n",
    "# TODO: Clean the full_name column\n",
    "# Issues to fix:\n",
    "# 1. Extra whitespace (leading/trailing and multiple spaces)\n",
    "# 2. Inconsistent case (some all caps, some lowercase)\n",
    "# 3. Missing values\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35af320",
   "metadata": {},
   "source": [
    "### üìã TASK 3: Clean the `salary` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean the salary column\n",
    "# Issues to fix:\n",
    "# 1. Currency symbol ($)\n",
    "# 2. Thousands separator (,)\n",
    "# 3. Decimal notation (.00)\n",
    "# 4. Convert to numeric type\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a780df3",
   "metadata": {},
   "source": [
    "### üìã TASK 4: Clean Date Columns (`hire_date`, `birth_date`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d376df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean hire_date\n",
    "# Issues to fix:\n",
    "# 1. Multiple date formats (2020-01-15, 15/01/2019, 01-Mar-2021, etc.)\n",
    "# 2. Invalid dates (\"invalid_date\")\n",
    "# 3. Convert to datetime type\n",
    "\n",
    "# Hint: pd.to_datetime() with dayfirst and errors parameters\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a35413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean birth_date\n",
    "# Similar issues as hire_date\n",
    "# Additional: Check for impossible dates (e.g., Feb 29 in non-leap year)\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510995a0",
   "metadata": {},
   "source": [
    "### üìã TASK 5: Clean the `email` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d207cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean and validate emails\n",
    "# Issues to fix:\n",
    "# 1. Some emails missing domain suffix (.com)\n",
    "# 2. Convert to lowercase\n",
    "# 3. Validate format (basic check)\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cecdce5",
   "metadata": {},
   "source": [
    "### üìã TASK 6: Standardize the `phone` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c382e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Standardize phone numbers to a consistent format\n",
    "# Current formats: (555) 123-4567, 555.234.5678, +1-555-345-6789, 5556789012, etc.\n",
    "# Target format: (XXX) XXX-XXXX or mark as missing if \"N/A\"\n",
    "\n",
    "# Hint: Extract only digits, then reformat\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa7e3f2",
   "metadata": {},
   "source": [
    "### üìã TASK 7: Standardize the `education` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cefa26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Standardize education values\n",
    "# Current variations:\n",
    "# - Bachelor's, Bachelor, Bachelors, bachelor's degree, bachelor\n",
    "# - Master's, Masters, MBA\n",
    "# - PhD\n",
    "# - Associate's, Associate\n",
    "# - High School\n",
    "# - Special: CPA, PMP (professional certifications)\n",
    "\n",
    "# Create a mapping dictionary and apply it\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93b65f",
   "metadata": {},
   "source": [
    "### üìã TASK 8: Clean `is_remote` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert is_remote to boolean\n",
    "# Current values: Yes, No, TRUE, FALSE, yes, no, true, false\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b77803",
   "metadata": {},
   "source": [
    "### üìã TASK 9: Handle `performance_rating` Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean performance_rating\n",
    "# Issues: Some values are -1 (invalid)\n",
    "# Valid range should be 1-5\n",
    "\n",
    "# Decision: What should we do with invalid ratings?\n",
    "# Option A: Set to NaN\n",
    "# Option B: Set to median\n",
    "# Option C: Keep as-is for investigation\n",
    "\n",
    "# Document your decision and implement it\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d096d31",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Handle Missing Values\n",
    "\n",
    "### üìã TASK 10: Analyze and Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values after initial cleaning\n",
    "print(\"Missing Values After Initial Cleaning:\")\n",
    "missing = df_clean.isnull().sum()\n",
    "missing_pct = (missing / len(df_clean) * 100).round(2)\n",
    "missing_report = pd.DataFrame({'count': missing, 'pct': missing_pct})\n",
    "print(missing_report[missing_report['count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11961cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Decide on missing value strategy for each column\n",
    "# \n",
    "# For each column with missing values, document:\n",
    "# 1. Why is it missing? (random, systematic, intentional)\n",
    "# 2. What's the impact of the missing data?\n",
    "# 3. What's your strategy? (drop, impute, keep as-is)\n",
    "\n",
    "# Example decisions:\n",
    "# - employee_id missing: Critical - cannot identify employee. Flag for HR review.\n",
    "# - full_name missing: Try to recover from email. If not possible, flag for review.\n",
    "# - termination_date missing: This is expected - means employee is still active!\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6097c47",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Detect and Handle Outliers\n",
    "\n",
    "### üìã TASK 11: Analyze Salary Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Detect salary outliers\n",
    "# 1. Calculate IQR boundaries\n",
    "# 2. Visualize the distribution\n",
    "# 3. Identify outliers\n",
    "# 4. Decide: Are these true outliers or valid extreme values?\n",
    "\n",
    "# Hint: Director-level salaries might look like outliers but are legitimate\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb9f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze salary by department and job level\n",
    "# This helps determine if \"outliers\" are actually expected for senior roles\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd1fdbd",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Feature Engineering\n",
    "\n",
    "### üìã TASK 12: Create Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the following features:\n",
    "\n",
    "# 1. age (from birth_date)\n",
    "\n",
    "# 2. tenure_years (from hire_date)\n",
    "\n",
    "# 3. is_active (True if termination_date is null)\n",
    "\n",
    "# 4. age_group (bins: Under 30, 30-39, 40-49, 50+)\n",
    "\n",
    "# 5. tenure_group (New: <1 year, Junior: 1-3, Mid: 3-5, Senior: 5+)\n",
    "\n",
    "# 6. salary_band (based on quartiles within department)\n",
    "\n",
    "# 7. Extract first_name and last_name from full_name\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6198828",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Data Validation\n",
    "\n",
    "### üìã TASK 13: Validate the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95740009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create validation checks\n",
    "\n",
    "# 1. All employee_ids should be unique (for non-null values)\n",
    "\n",
    "# 2. Age should be between 18 and 100\n",
    "\n",
    "# 3. Hire date should be before today and after 2000\n",
    "\n",
    "# 4. Salary should be positive\n",
    "\n",
    "# 5. Performance rating should be 1-5 or null\n",
    "\n",
    "# 6. Termination date (if exists) should be after hire date\n",
    "\n",
    "# 7. Manager ID should exist in employee_id list (except for top executives)\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation summary function\n",
    "def validate_hr_data(df):\n",
    "    \"\"\"Run validation checks on HR data and return issues.\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # TODO: Add your validation checks here\n",
    "    # Example:\n",
    "    # if df['employee_id'].duplicated().any():\n",
    "    #     issues.append(\"Duplicate employee IDs found\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "# Run validation\n",
    "issues = validate_hr_data(df_clean)\n",
    "print(\"Validation Issues:\")\n",
    "for issue in issues:\n",
    "    print(f\"  ‚ö†Ô∏è {issue}\")\n",
    "    \n",
    "if not issues:\n",
    "    print(\"  ‚úÖ All validation checks passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf984e",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Final Output\n",
    "\n",
    "### üìã TASK 14: Create the Final Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and order final columns\n",
    "final_columns = [\n",
    "    # Identifiers\n",
    "    'employee_id', 'full_name', 'first_name', 'last_name',\n",
    "    # Contact\n",
    "    'email', 'phone',\n",
    "    # Demographics\n",
    "    'birth_date', 'age', 'age_group',\n",
    "    # Employment\n",
    "    'hire_date', 'tenure_years', 'tenure_group', 'termination_date', 'is_active',\n",
    "    # Position\n",
    "    'department', 'job_title', 'manager_id',\n",
    "    # Compensation\n",
    "    'salary', 'salary_band',\n",
    "    # Other\n",
    "    'education', 'performance_rating', 'is_remote'\n",
    "]\n",
    "\n",
    "# TODO: Create final dataframe with selected columns\n",
    "# Note: Only include columns that exist in df_clean\n",
    "\n",
    "# df_final = df_clean[[col for col in final_columns if col in df_clean.columns]]\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef0fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final data quality summary\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL DATA QUALITY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal Records: {len(df_final)}\")\n",
    "print(f\"Total Columns: {len(df_final.columns)}\")\n",
    "print(f\"\\nMissing Values:\")\n",
    "print(df_final.isnull().sum()[df_final.isnull().sum() > 0])\n",
    "\n",
    "print(f\"\\nData Types:\")\n",
    "print(df_final.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data\n",
    "df_final.to_csv('data/cleaned_hr_data.csv', index=False)\n",
    "print(\"‚úÖ Cleaned data saved to 'data/cleaned_hr_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0caf6e",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Documentation for Stakeholders\n",
    "\n",
    "### üìã TASK 15: Create a Data Cleaning Report\n",
    "\n",
    "Create a summary that you could share with the HR Director. This should be non-technical and focus on:\n",
    "1. What issues were found\n",
    "2. What decisions were made\n",
    "3. What the data looks like now\n",
    "4. Any recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e69d20d",
   "metadata": {},
   "source": [
    "## üìä HR Data Cleaning Report\n",
    "\n",
    "**Prepared by:** [Your Name]  \n",
    "**Date:** [Date]  \n",
    "**Dataset:** Employee Records\n",
    "\n",
    "---\n",
    "\n",
    "### Executive Summary\n",
    "\n",
    "[Write a 2-3 sentence summary of what you did and the outcome]\n",
    "\n",
    "---\n",
    "\n",
    "### Data Issues Found\n",
    "\n",
    "| Category | Issue | Records Affected | Resolution |\n",
    "|----------|-------|------------------|------------|\n",
    "| Missing Data | Employee names missing | X records | ? |\n",
    "| Formatting | Inconsistent date formats | X records | Standardized to YYYY-MM-DD |\n",
    "| Data Quality | Invalid performance ratings | X records | ? |\n",
    "| ... | ... | ... | ... |\n",
    "\n",
    "---\n",
    "\n",
    "### Key Decisions Made\n",
    "\n",
    "1. **[Decision 1]**: [Explanation of why this decision was made]\n",
    "2. **[Decision 2]**: [Explanation]\n",
    "3. ...\n",
    "\n",
    "---\n",
    "\n",
    "### Data Quality After Cleaning\n",
    "\n",
    "- Total employees in dataset: X\n",
    "- Active employees: X\n",
    "- Terminated employees: X\n",
    "- Records flagged for HR review: X\n",
    "\n",
    "---\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **[Recommendation 1]**: [e.g., Implement data validation at entry]\n",
    "2. **[Recommendation 2]**: [e.g., Regular data quality audits]\n",
    "3. ...\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "The cleaned dataset is ready for:\n",
    "- [ ] Salary analysis\n",
    "- [ ] Retention analysis\n",
    "- [ ] Performance insights\n",
    "- [ ] Workforce demographics report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790b06c",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Bonus Challenges\n",
    "\n",
    "If you finish early, try these additional challenges:\n",
    "\n",
    "### Challenge 1: Salary Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze if there are salary disparities by:\n",
    "# - Department (controlling for job level)\n",
    "# - Tenure (do longer-tenured employees earn more?)\n",
    "# - Remote vs. in-office\n",
    "\n",
    "# Create visualizations to support your analysis\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a4f06",
   "metadata": {},
   "source": [
    "### Challenge 2: Retention Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze terminated employees:\n",
    "# - What's the average tenure of terminated employees?\n",
    "# - Which departments have highest turnover?\n",
    "# - Is there a pattern in performance ratings of terminated employees?\n",
    "\n",
    "# Your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f656ff",
   "metadata": {},
   "source": [
    "### Challenge 3: Create an Automated Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113dbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a function that takes raw HR data and returns cleaned data\n",
    "# This should be reusable for future data updates\n",
    "\n",
    "def clean_hr_data(df_raw):\n",
    "    \"\"\"\n",
    "    Clean and transform raw HR data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_raw : pandas.DataFrame\n",
    "        Raw HR data with messy formatting\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Cleaned and transformed HR data\n",
    "    \"\"\"\n",
    "    df = df_raw.copy()\n",
    "    \n",
    "    # TODO: Add all your cleaning steps here\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Test your pipeline\n",
    "# df_test = clean_hr_data(df)\n",
    "# print(df_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d709539",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Reflection Questions\n",
    "\n",
    "After completing this project, reflect on the following:\n",
    "\n",
    "1. **What was the most challenging part of cleaning this data?**\n",
    "\n",
    "2. **What decisions did you have to make that could have gone either way?**\n",
    "\n",
    "3. **How would you prevent these data quality issues in the future?**\n",
    "\n",
    "4. **What additional information would have helped you clean this data better?**\n",
    "\n",
    "5. **How would you communicate your cleaning decisions to a non-technical stakeholder?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29b85a",
   "metadata": {},
   "source": [
    "---\n",
    "## üèÜ Project Rubric\n",
    "\n",
    "| Criteria | Points | Description |\n",
    "|----------|--------|-------------|\n",
    "| **Data Assessment** | 15 | Thoroughly documented all data issues |\n",
    "| **Missing Values** | 15 | Appropriately handled missing data with clear rationale |\n",
    "| **Type Conversion** | 15 | Correctly converted dates, numbers, and categories |\n",
    "| **Text Cleaning** | 15 | Standardized names, emails, phones, education |\n",
    "| **Feature Engineering** | 15 | Created useful derived features |\n",
    "| **Validation** | 10 | Implemented data quality checks |\n",
    "| **Documentation** | 15 | Clear stakeholder report with decisions explained |\n",
    "| **Total** | 100 | |\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations on completing the Data Cleaning Mini-Project!** üéâ\n",
    "\n",
    "This project demonstrates your ability to:\n",
    "- Work with messy, real-world data\n",
    "- Make and document data cleaning decisions\n",
    "- Communicate technical work to non-technical stakeholders\n",
    "- Create reproducible data cleaning processes\n",
    "\n",
    "These are essential skills for any Data Analyst role!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
