{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e689db",
   "metadata": {},
   "source": [
    "# Feature Engineering Basics\n",
    "\n",
    "**Module 4: Data Cleaning & Transformation**\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand what feature engineering is and why it matters\n",
    "- Create new features from existing data\n",
    "- Apply binning and discretization techniques\n",
    "- Encode categorical variables for analysis\n",
    "- Transform numerical features\n",
    "\n",
    "## Business Context\n",
    "> \"Feature engineering is where domain knowledge meets data science. The best features tell a story that raw data cannot.\"\n",
    "\n",
    "Feature engineering is the process of creating new variables from existing data to improve analysis and modeling. As a Data Analyst, this skill helps you uncover insights that aren't immediately visible in raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401774bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483130e",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. What is Feature Engineering?\n",
    "\n",
    "**Feature engineering** is the process of using domain knowledge to create new variables (features) that make patterns in data more apparent.\n",
    "\n",
    "### Types of Feature Engineering\n",
    "\n",
    "| Type | Description | Example |\n",
    "|------|-------------|---------|\n",
    "| **Extraction** | Pull out parts of existing features | Year from date, domain from email |\n",
    "| **Aggregation** | Combine multiple values | Total spend, average rating |\n",
    "| **Transformation** | Change feature representation | Log scale, normalization |\n",
    "| **Binning** | Convert continuous to categorical | Age groups, income brackets |\n",
    "| **Encoding** | Convert categories to numbers | One-hot, label encoding |\n",
    "| **Interaction** | Combine features | Price per unit, BMI |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b79888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic e-commerce dataset\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "customers = pd.DataFrame({\n",
    "    'customer_id': range(1001, 1001 + n),\n",
    "    'registration_date': pd.date_range('2020-01-01', periods=n, freq='D'),\n",
    "    'birth_date': pd.to_datetime('1990-01-01') + pd.to_timedelta(\n",
    "        np.random.randint(-10000, 10000, n), unit='D'\n",
    "    ),\n",
    "    'gender': np.random.choice(['M', 'F', 'Other'], n, p=[0.48, 0.48, 0.04]),\n",
    "    'city': np.random.choice(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'], n),\n",
    "    'total_orders': np.random.poisson(5, n),\n",
    "    'total_spend': np.random.exponential(500, n),\n",
    "    'last_order_date': pd.date_range('2023-06-01', periods=n, freq='h'),\n",
    "    'email': [f'customer_{i}@{np.random.choice([\"gmail.com\", \"yahoo.com\", \"outlook.com\"])}' \n",
    "              for i in range(n)],\n",
    "    'subscription_plan': np.random.choice(['Free', 'Basic', 'Premium', 'Enterprise'], n, \n",
    "                                          p=[0.4, 0.3, 0.2, 0.1])\n",
    "})\n",
    "\n",
    "print(\"E-commerce Customer Dataset:\")\n",
    "print(f\"Shape: {customers.shape}\")\n",
    "customers.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c182d",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Feature Extraction\n",
    "\n",
    "Create new features by extracting information from existing ones.\n",
    "\n",
    "### 2.1 Date/Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280bfbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date components\n",
    "customers['registration_year'] = customers['registration_date'].dt.year\n",
    "customers['registration_month'] = customers['registration_date'].dt.month\n",
    "customers['registration_quarter'] = customers['registration_date'].dt.quarter\n",
    "customers['registration_day_of_week'] = customers['registration_date'].dt.dayofweek\n",
    "customers['registration_day_name'] = customers['registration_date'].dt.day_name()\n",
    "customers['registered_on_weekend'] = customers['registration_date'].dt.dayofweek >= 5\n",
    "\n",
    "print(\"Date Features Extracted:\")\n",
    "print(customers[['registration_date', 'registration_year', 'registration_month', \n",
    "                  'registration_quarter', 'registration_day_name', 'registered_on_weekend']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477372d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate age and customer tenure\n",
    "today = pd.Timestamp.today()\n",
    "\n",
    "# Age in years\n",
    "customers['age'] = ((today - customers['birth_date']).dt.days / 365.25).astype(int)\n",
    "\n",
    "# Customer tenure (days since registration)\n",
    "customers['tenure_days'] = (today - customers['registration_date']).dt.days\n",
    "customers['tenure_months'] = (customers['tenure_days'] / 30).round(1)\n",
    "\n",
    "# Days since last order\n",
    "customers['days_since_last_order'] = (today - customers['last_order_date']).dt.days\n",
    "\n",
    "print(\"Calculated Time Features:\")\n",
    "print(customers[['customer_id', 'age', 'tenure_days', 'tenure_months', \n",
    "                  'days_since_last_order']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59bbe0b",
   "metadata": {},
   "source": [
    "### 2.2 Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc64ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract email domain\n",
    "customers['email_domain'] = customers['email'].str.split('@').str[1]\n",
    "\n",
    "# Create email provider category\n",
    "customers['email_provider'] = customers['email_domain'].map({\n",
    "    'gmail.com': 'Google',\n",
    "    'yahoo.com': 'Yahoo',\n",
    "    'outlook.com': 'Microsoft'\n",
    "})\n",
    "\n",
    "print(\"Email Features:\")\n",
    "print(customers[['email', 'email_domain', 'email_provider']].head())\n",
    "\n",
    "print(\"\\nEmail Provider Distribution:\")\n",
    "print(customers['email_provider'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d5d95",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Binning (Discretization)\n",
    "\n",
    "Convert continuous variables into categorical groups.\n",
    "\n",
    "### 3.1 Equal-Width Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29719f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin age into equal-width groups\n",
    "customers['age_group_equal'] = pd.cut(\n",
    "    customers['age'],\n",
    "    bins=[0, 25, 35, 45, 55, 100],\n",
    "    labels=['18-25', '26-35', '36-45', '46-55', '55+']\n",
    ")\n",
    "\n",
    "print(\"Age Groups (Equal Width):\")\n",
    "print(customers['age_group_equal'].value_counts().sort_index())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(customers['age'], bins=30, edgecolor='black')\n",
    "axes[0].set_title('Original Age Distribution')\n",
    "axes[0].set_xlabel('Age')\n",
    "\n",
    "customers['age_group_equal'].value_counts().sort_index().plot(kind='bar', ax=axes[1], color='skyblue')\n",
    "axes[1].set_title('Age Groups (Binned)')\n",
    "axes[1].set_xlabel('Age Group')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47f6ed",
   "metadata": {},
   "source": [
    "### 3.2 Equal-Frequency Binning (Quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4270374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin total_spend into quartiles\n",
    "customers['spend_quartile'] = pd.qcut(\n",
    "    customers['total_spend'],\n",
    "    q=4,\n",
    "    labels=['Low', 'Medium', 'High', 'Very High']\n",
    ")\n",
    "\n",
    "print(\"Spend Quartiles:\")\n",
    "print(customers['spend_quartile'].value_counts().sort_index())\n",
    "\n",
    "# Show the actual cutoff values\n",
    "print(\"\\nQuartile boundaries:\")\n",
    "for i, q in enumerate([0, 0.25, 0.5, 0.75, 1.0]):\n",
    "    print(f\"  {q*100:.0f}%: ${customers['total_spend'].quantile(q):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96828431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom bins based on business logic\n",
    "# Example: Customer segments based on spending\n",
    "customers['customer_segment'] = pd.cut(\n",
    "    customers['total_spend'],\n",
    "    bins=[0, 100, 500, 1000, np.inf],\n",
    "    labels=['Bronze', 'Silver', 'Gold', 'Platinum']\n",
    ")\n",
    "\n",
    "print(\"Customer Segments (Business-Defined):\")\n",
    "segment_stats = customers.groupby('customer_segment').agg({\n",
    "    'customer_id': 'count',\n",
    "    'total_spend': ['mean', 'min', 'max'],\n",
    "    'total_orders': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(segment_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5016d86",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Ratio and Interaction Features\n",
    "\n",
    "Create new features by combining existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate derived metrics\n",
    "\n",
    "# Average order value\n",
    "customers['avg_order_value'] = customers['total_spend'] / customers['total_orders'].replace(0, np.nan)\n",
    "\n",
    "# Orders per month (customer tenure)\n",
    "customers['orders_per_month'] = customers['total_orders'] / (customers['tenure_months'].replace(0, 1))\n",
    "\n",
    "# Spend per month\n",
    "customers['spend_per_month'] = customers['total_spend'] / (customers['tenure_months'].replace(0, 1))\n",
    "\n",
    "print(\"Derived Metrics:\")\n",
    "print(customers[['customer_id', 'total_orders', 'total_spend', 'tenure_months',\n",
    "                  'avg_order_value', 'orders_per_month', 'spend_per_month']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM (Recency, Frequency, Monetary) - Classic customer analysis\n",
    "# Recency: Days since last order (lower = better)\n",
    "# Frequency: Total orders (higher = better)\n",
    "# Monetary: Total spend (higher = better)\n",
    "\n",
    "# Score each dimension (1-5, with 5 being best)\n",
    "customers['R_score'] = pd.qcut(customers['days_since_last_order'], q=5, \n",
    "                                labels=[5, 4, 3, 2, 1])  # Reversed: low recency = high score\n",
    "\n",
    "customers['F_score'] = pd.qcut(customers['total_orders'].rank(method='first'), q=5, \n",
    "                                labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "customers['M_score'] = pd.qcut(customers['total_spend'].rank(method='first'), q=5, \n",
    "                                labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Create RFM segment\n",
    "customers['RFM_score'] = (customers['R_score'].astype(str) + \n",
    "                          customers['F_score'].astype(str) + \n",
    "                          customers['M_score'].astype(str))\n",
    "\n",
    "customers['RFM_total'] = (customers['R_score'].astype(int) + \n",
    "                          customers['F_score'].astype(int) + \n",
    "                          customers['M_score'].astype(int))\n",
    "\n",
    "print(\"RFM Analysis:\")\n",
    "print(customers[['customer_id', 'days_since_last_order', 'total_orders', 'total_spend',\n",
    "                  'R_score', 'F_score', 'M_score', 'RFM_score', 'RFM_total']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c624b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer value segment based on RFM\n",
    "def rfm_segment(row):\n",
    "    if row['RFM_total'] >= 12:\n",
    "        return 'Champions'\n",
    "    elif row['RFM_total'] >= 9:\n",
    "        return 'Loyal Customers'\n",
    "    elif row['RFM_total'] >= 6:\n",
    "        return 'Potential Loyalists'\n",
    "    elif row['RFM_total'] >= 4:\n",
    "        return 'At Risk'\n",
    "    else:\n",
    "        return 'Lost'\n",
    "\n",
    "customers['rfm_segment'] = customers.apply(rfm_segment, axis=1)\n",
    "\n",
    "print(\"\\nRFM Segments:\")\n",
    "segment_summary = customers.groupby('rfm_segment').agg({\n",
    "    'customer_id': 'count',\n",
    "    'total_spend': 'mean',\n",
    "    'total_orders': 'mean'\n",
    "}).round(2)\n",
    "segment_summary.columns = ['Count', 'Avg Spend', 'Avg Orders']\n",
    "print(segment_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d89477c",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Encoding Categorical Variables\n",
    "\n",
    "Convert categorical data into numerical format.\n",
    "\n",
    "### 5.1 Label Encoding (Ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8493a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for ordinal categories\n",
    "# Use when there's a natural order\n",
    "\n",
    "# Subscription plan has a natural order\n",
    "plan_order = {'Free': 0, 'Basic': 1, 'Premium': 2, 'Enterprise': 3}\n",
    "customers['subscription_level'] = customers['subscription_plan'].map(plan_order)\n",
    "\n",
    "print(\"Label Encoding (Ordinal):\")\n",
    "print(customers[['subscription_plan', 'subscription_level']].drop_duplicates().sort_values('subscription_level'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a73dd",
   "metadata": {},
   "source": [
    "### 5.2 One-Hot Encoding (Nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb0de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for nominal categories (no natural order)\n",
    "# Use for: city, gender, color, etc.\n",
    "\n",
    "# Method 1: pd.get_dummies()\n",
    "city_dummies = pd.get_dummies(customers['city'], prefix='city')\n",
    "print(\"One-Hot Encoding (City):\")\n",
    "print(city_dummies.head())\n",
    "\n",
    "# Add to dataframe\n",
    "customers_encoded = pd.concat([customers, city_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode multiple columns at once\n",
    "encoded_df = pd.get_dummies(\n",
    "    customers[['gender', 'city', 'email_provider']],\n",
    "    drop_first=True  # Avoid dummy variable trap\n",
    ")\n",
    "\n",
    "print(\"\\nOne-Hot Encoding (Multiple Columns, drop_first=True):\")\n",
    "print(encoded_df.head())\n",
    "\n",
    "print(f\"\\nOriginal columns: gender, city, email_provider\")\n",
    "print(f\"Encoded columns: {encoded_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab35e4",
   "metadata": {},
   "source": [
    "### 5.3 Binary Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary flags from conditions\n",
    "\n",
    "# Is the customer active? (ordered in last 30 days)\n",
    "customers['is_active'] = (customers['days_since_last_order'] <= 30).astype(int)\n",
    "\n",
    "# Is the customer a high spender? (above median)\n",
    "median_spend = customers['total_spend'].median()\n",
    "customers['is_high_spender'] = (customers['total_spend'] > median_spend).astype(int)\n",
    "\n",
    "# Is premium customer?\n",
    "customers['is_premium'] = customers['subscription_plan'].isin(['Premium', 'Enterprise']).astype(int)\n",
    "\n",
    "print(\"Binary Features:\")\n",
    "print(customers[['customer_id', 'days_since_last_order', 'is_active', \n",
    "                  'total_spend', 'is_high_spender', \n",
    "                  'subscription_plan', 'is_premium']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bbcd05",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Numerical Transformations\n",
    "\n",
    "Transform numerical features to improve analysis.\n",
    "\n",
    "### 6.1 Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation for skewed data\n",
    "# Useful for: monetary values, counts, highly skewed distributions\n",
    "\n",
    "# Check skewness before\n",
    "print(f\"Original total_spend skewness: {customers['total_spend'].skew():.2f}\")\n",
    "\n",
    "# Apply log transformation (add 1 to handle zeros)\n",
    "customers['log_total_spend'] = np.log1p(customers['total_spend'])\n",
    "\n",
    "print(f\"Log-transformed skewness: {customers['log_total_spend'].skew():.2f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(customers['total_spend'], bins=50, edgecolor='black')\n",
    "axes[0].set_title('Original Distribution (Skewed)')\n",
    "axes[0].set_xlabel('Total Spend ($)')\n",
    "\n",
    "axes[1].hist(customers['log_total_spend'], bins=50, edgecolor='black', color='green')\n",
    "axes[1].set_title('Log-Transformed Distribution')\n",
    "axes[1].set_xlabel('Log(Total Spend)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edfa219",
   "metadata": {},
   "source": [
    "### 6.2 Standardization (Z-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization: Mean = 0, Std = 1\n",
    "# Useful for: comparing different scales, clustering, some ML algorithms\n",
    "\n",
    "def standardize(series):\n",
    "    \"\"\"Standardize a series to have mean=0 and std=1\"\"\"\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "customers['spend_standardized'] = standardize(customers['total_spend'])\n",
    "customers['orders_standardized'] = standardize(customers['total_orders'])\n",
    "customers['tenure_standardized'] = standardize(customers['tenure_days'])\n",
    "\n",
    "print(\"Standardized Features (Z-Scores):\")\n",
    "print(customers[['total_spend', 'spend_standardized', \n",
    "                  'total_orders', 'orders_standardized']].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582290d7",
   "metadata": {},
   "source": [
    "### 6.3 Min-Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7eb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization: Scale to [0, 1]\n",
    "# Useful for: neural networks, when you need bounded values\n",
    "\n",
    "def min_max_normalize(series):\n",
    "    \"\"\"Normalize a series to range [0, 1]\"\"\"\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "customers['spend_normalized'] = min_max_normalize(customers['total_spend'])\n",
    "customers['orders_normalized'] = min_max_normalize(customers['total_orders'])\n",
    "\n",
    "print(\"Min-Max Normalized Features:\")\n",
    "print(customers[['total_spend', 'spend_normalized', \n",
    "                  'total_orders', 'orders_normalized']].describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d76d6f",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Aggregation Features\n",
    "\n",
    "Create features by aggregating data from related records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e6ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transaction-level data\n",
    "np.random.seed(42)\n",
    "n_transactions = 2000\n",
    "\n",
    "transactions = pd.DataFrame({\n",
    "    'transaction_id': range(1, n_transactions + 1),\n",
    "    'customer_id': np.random.choice(customers['customer_id'], n_transactions),\n",
    "    'transaction_date': pd.date_range('2023-01-01', periods=n_transactions, freq='4h'),\n",
    "    'amount': np.random.exponential(100, n_transactions),\n",
    "    'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Home', 'Books'], n_transactions)\n",
    "})\n",
    "\n",
    "print(\"Transaction Data:\")\n",
    "print(transactions.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1542a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate transaction data per customer\n",
    "customer_agg = transactions.groupby('customer_id').agg({\n",
    "    'transaction_id': 'count',\n",
    "    'amount': ['sum', 'mean', 'std', 'min', 'max'],\n",
    "    'transaction_date': ['min', 'max'],\n",
    "    'category': 'nunique'\n",
    "})\n",
    "\n",
    "# Flatten column names\n",
    "customer_agg.columns = ['_'.join(col).strip() for col in customer_agg.columns]\n",
    "customer_agg = customer_agg.reset_index()\n",
    "\n",
    "# Rename for clarity\n",
    "customer_agg.columns = [\n",
    "    'customer_id', 'num_transactions', 'total_amount', 'avg_amount', \n",
    "    'std_amount', 'min_amount', 'max_amount', 'first_transaction', \n",
    "    'last_transaction', 'num_categories'\n",
    "]\n",
    "\n",
    "print(\"\\nAggregated Customer Features:\")\n",
    "print(customer_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create category-specific features\n",
    "category_spend = transactions.pivot_table(\n",
    "    index='customer_id',\n",
    "    columns='category',\n",
    "    values='amount',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Add prefix to column names\n",
    "category_spend.columns = ['customer_id'] + [f'spend_{cat.lower()}' for cat in category_spend.columns[1:]]\n",
    "\n",
    "print(\"Category-Specific Spending:\")\n",
    "print(category_spend.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3a0d98",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Practical Exercises\n",
    "\n",
    "### Exercise 1: Create Employee Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc48c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employee dataset\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "\n",
    "employees = pd.DataFrame({\n",
    "    'employee_id': range(1, n + 1),\n",
    "    'hire_date': pd.date_range('2015-01-01', periods=n, freq='W'),\n",
    "    'birth_date': pd.to_datetime('1985-01-01') + pd.to_timedelta(\n",
    "        np.random.randint(-5000, 5000, n), unit='D'\n",
    "    ),\n",
    "    'department': np.random.choice(['Sales', 'IT', 'HR', 'Marketing', 'Finance'], n),\n",
    "    'salary': np.random.normal(60000, 15000, n),\n",
    "    'performance_rating': np.random.choice([1, 2, 3, 4, 5], n, p=[0.05, 0.15, 0.40, 0.30, 0.10]),\n",
    "    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n, p=[0.2, 0.5, 0.25, 0.05]),\n",
    "    'is_remote': np.random.choice([True, False], n, p=[0.3, 0.7])\n",
    "})\n",
    "\n",
    "print(\"Employee Data:\")\n",
    "employees.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93346a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the following features:\n",
    "# 1. age (from birth_date)\n",
    "# 2. tenure_years (from hire_date)\n",
    "# 3. age_group (bins: 20-30, 30-40, 40-50, 50+)\n",
    "# 4. salary_band (Low, Medium, High, Very High based on quartiles)\n",
    "# 5. education_level (ordinal: 0, 1, 2, 3)\n",
    "# 6. is_high_performer (performance_rating >= 4)\n",
    "# 7. salary_per_experience_year (salary / tenure_years)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d897a97",
   "metadata": {},
   "source": [
    "### Exercise 2: RFM Analysis for Retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retail transaction data\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "retail = pd.DataFrame({\n",
    "    'customer_id': np.random.randint(100, 200, n),\n",
    "    'purchase_date': pd.date_range('2023-01-01', periods=n, freq='8h'),\n",
    "    'purchase_amount': np.random.exponential(75, n)\n",
    "})\n",
    "\n",
    "print(\"Retail Transactions:\")\n",
    "print(retail.head())\n",
    "print(f\"\\nUnique customers: {retail['customer_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d275d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform RFM Analysis\n",
    "# 1. Calculate Recency (days since last purchase for each customer)\n",
    "# 2. Calculate Frequency (number of purchases per customer)\n",
    "# 3. Calculate Monetary (total spend per customer)\n",
    "# 4. Score each dimension 1-5 using quintiles\n",
    "# 5. Create customer segments based on RFM scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6fd0a4",
   "metadata": {},
   "source": [
    "### Exercise 3: Feature Engineering for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea087d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Website session data\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "sessions = pd.DataFrame({\n",
    "    'session_id': range(1, n + 1),\n",
    "    'user_id': np.random.randint(1, 101, n),\n",
    "    'session_start': pd.date_range('2024-01-01', periods=n, freq='30min'),\n",
    "    'duration_seconds': np.random.exponential(300, n),\n",
    "    'pages_viewed': np.random.poisson(5, n),\n",
    "    'device': np.random.choice(['Mobile', 'Desktop', 'Tablet'], n, p=[0.6, 0.3, 0.1]),\n",
    "    'source': np.random.choice(['Organic', 'Paid', 'Social', 'Direct'], n),\n",
    "    'converted': np.random.choice([0, 1], n, p=[0.9, 0.1])\n",
    "})\n",
    "\n",
    "print(\"Session Data:\")\n",
    "sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create features that might help predict conversion:\n",
    "# 1. hour_of_day (from session_start)\n",
    "# 2. day_of_week\n",
    "# 3. is_weekend\n",
    "# 4. duration_minutes (from duration_seconds)\n",
    "# 5. pages_per_minute\n",
    "# 6. is_mobile (binary: 1 if Mobile, 0 otherwise)\n",
    "# 7. One-hot encode 'source'\n",
    "# 8. User-level aggregates (avg_session_duration, total_sessions, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee29c8b",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Key Takeaways\n",
    "\n",
    "### ‚úÖ Feature Engineering Best Practices\n",
    "\n",
    "1. **Start with domain knowledge** - What makes sense for your business?\n",
    "2. **Extract date/time features** - Year, month, day of week, is_weekend\n",
    "3. **Create ratio features** - Value per unit, rate of change\n",
    "4. **Use binning wisely** - Business-defined bins vs. quantiles\n",
    "5. **Encode properly** - Label encoding for ordinal, one-hot for nominal\n",
    "6. **Aggregate related data** - Sum, mean, count, unique count\n",
    "\n",
    "### üìã Quick Reference\n",
    "\n",
    "```python\n",
    "# Binning\n",
    "pd.cut(df['col'], bins=[0, 10, 20, 30])  # Custom bins\n",
    "pd.qcut(df['col'], q=4)  # Quantile-based bins\n",
    "\n",
    "# Encoding\n",
    "pd.get_dummies(df['col'], drop_first=True)  # One-hot\n",
    "df['col'].map({'Low': 0, 'High': 1})  # Label encoding\n",
    "\n",
    "# Transformations\n",
    "np.log1p(df['col'])  # Log transform (handles zeros)\n",
    "(df['col'] - df['col'].mean()) / df['col'].std()  # Standardize\n",
    "\n",
    "# Date features\n",
    "df['date'].dt.year / .dt.month / .dt.dayofweek\n",
    "\n",
    "# Aggregation\n",
    "df.groupby('key').agg({'val': ['sum', 'mean', 'count']})\n",
    "```\n",
    "\n",
    "### ‚ö†Ô∏è Common Mistakes\n",
    "\n",
    "1. Using label encoding for nominal categories (no order)\n",
    "2. Not handling zeros before log transformation\n",
    "3. Creating too many one-hot columns (dimensionality explosion)\n",
    "4. Not documenting feature creation logic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
