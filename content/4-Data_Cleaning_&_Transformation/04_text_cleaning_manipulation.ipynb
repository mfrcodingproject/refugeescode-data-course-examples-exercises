{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df22cbc",
   "metadata": {},
   "source": [
    "# Text Cleaning & Manipulation\n",
    "\n",
    "**Module 4: Data Cleaning & Transformation**\n",
    "\n",
    "## Learning Objectives\n",
    "- Master the pandas `.str` accessor for text operations\n",
    "- Apply regular expressions for pattern matching\n",
    "- Clean and standardize text data\n",
    "- Extract useful information from text fields\n",
    "\n",
    "## Business Context\n",
    "> \"Text data is messy by nature. Names have typos, emails have different formats, and free-text fields are chaos!\"\n",
    "\n",
    "As a Data Analyst, you'll frequently encounter text data that needs cleaning before analysis. This notebook covers the essential techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46adfba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"✓ Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169eab8a",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. The `.str` Accessor\n",
    "\n",
    "Pandas provides the `.str` accessor to apply string methods to entire columns.\n",
    "\n",
    "### Basic String Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data with messy text\n",
    "customers = pd.DataFrame({\n",
    "    'name': ['  alice SMITH  ', 'BOB jones', 'Charlie Brown', '  diana PRINCE', 'EVE   '],\n",
    "    'email': ['Alice.Smith@GMAIL.com', 'bob@yahoo.COM', 'CHARLIE@outlook.com', \n",
    "              'diana.prince@Company.CO.UK', 'eve@HOTMAIL.com'],\n",
    "    'phone': ['555-123-4567', '(555) 234-5678', '555.345.6789', '5554567890', '+1 555 567 8901'],\n",
    "    'address': ['123 Main St, New York, NY 10001', \n",
    "                '456 Oak Ave, Los Angeles, CA 90001',\n",
    "                '789 Pine Rd, Chicago, IL 60601',\n",
    "                '321 Elm Blvd, Houston, TX 77001',\n",
    "                '654 Maple Dr, Phoenix, AZ 85001']\n",
    "})\n",
    "\n",
    "print(\"Original customer data:\")\n",
    "print(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case conversion\n",
    "print(\"=== Case Conversion ===\")\n",
    "print(f\"\\nOriginal names: {customers['name'].tolist()}\")\n",
    "print(f\"lowercase: {customers['name'].str.lower().tolist()}\")\n",
    "print(f\"UPPERCASE: {customers['name'].str.upper().tolist()}\")\n",
    "print(f\"Title Case: {customers['name'].str.title().tolist()}\")\n",
    "print(f\"Capitalize: {customers['name'].str.capitalize().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitespace handling\n",
    "print(\"=== Whitespace Handling ===\")\n",
    "print(f\"\\nOriginal: {customers['name'].tolist()}\")\n",
    "print(f\"strip(): {customers['name'].str.strip().tolist()}\")\n",
    "print(f\"lstrip(): {customers['name'].str.lstrip().tolist()}\")\n",
    "print(f\"rstrip(): {customers['name'].str.rstrip().tolist()}\")\n",
    "\n",
    "# Clean and standardize names\n",
    "customers['name_clean'] = customers['name'].str.strip().str.title()\n",
    "print(f\"\\nCleaned: {customers['name_clean'].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a33306",
   "metadata": {},
   "source": [
    "### String Length and Content Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de828b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length operations\n",
    "print(\"=== Length Operations ===\")\n",
    "customers['name_length'] = customers['name_clean'].str.len()\n",
    "print(customers[['name_clean', 'name_length']])\n",
    "\n",
    "# Word count\n",
    "customers['word_count'] = customers['name_clean'].str.split().str.len()\n",
    "print(\"\\nWith word count:\")\n",
    "print(customers[['name_clean', 'name_length', 'word_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content checks\n",
    "print(\"=== Content Checks ===\")\n",
    "\n",
    "# Check if email contains gmail\n",
    "print(\"\\nEmails containing 'gmail':\")\n",
    "print(customers['email'].str.lower().str.contains('gmail'))\n",
    "\n",
    "# Check if string starts/ends with specific text\n",
    "print(\"\\nAddresses starting with digit:\")\n",
    "print(customers['address'].str[0].str.isdigit())\n",
    "\n",
    "# Check if phone is numeric only\n",
    "print(\"\\nPhones (digits only):\")\n",
    "print(customers['phone'].str.replace(r'\\D', '', regex=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28ed4d",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Splitting and Extracting\n",
    "\n",
    "Extract parts of strings or split into multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split names into first and last\n",
    "customers[['first_name', 'last_name']] = customers['name_clean'].str.split(' ', n=1, expand=True)\n",
    "\n",
    "print(\"=== Split Names ===\")\n",
    "print(customers[['name_clean', 'first_name', 'last_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract email parts\n",
    "customers['email_clean'] = customers['email'].str.lower()\n",
    "customers['email_username'] = customers['email_clean'].str.split('@').str[0]\n",
    "customers['email_domain'] = customers['email_clean'].str.split('@').str[1]\n",
    "\n",
    "print(\"=== Email Parts ===\")\n",
    "print(customers[['email_clean', 'email_username', 'email_domain']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8543397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract address components\n",
    "# Pattern: Street, City, State ZIP\n",
    "address_parts = customers['address'].str.split(', ', expand=True)\n",
    "address_parts.columns = ['street', 'city', 'state_zip']\n",
    "\n",
    "# Further split state and zip\n",
    "address_parts[['state', 'zip']] = address_parts['state_zip'].str.split(' ', expand=True)\n",
    "\n",
    "print(\"=== Address Components ===\")\n",
    "print(address_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a6c22d",
   "metadata": {},
   "source": [
    "### Slicing Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6fb26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String slicing with .str[]\n",
    "print(\"=== String Slicing ===\")\n",
    "print(f\"\\nOriginal emails: {customers['email_clean'].tolist()}\")\n",
    "print(f\"First 5 chars: {customers['email_clean'].str[:5].tolist()}\")\n",
    "print(f\"Last 4 chars: {customers['email_clean'].str[-4:].tolist()}\")\n",
    "\n",
    "# Get initials\n",
    "customers['initials'] = customers['first_name'].str[0] + customers['last_name'].str[0]\n",
    "print(f\"\\nInitials: {customers['initials'].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6418ba1f",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. String Replacement\n",
    "\n",
    "Replace text patterns within strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694cf04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic replacement\n",
    "print(\"=== Basic Replacement ===\")\n",
    "print(f\"\\nOriginal phones: {customers['phone'].tolist()}\")\n",
    "\n",
    "# Remove all non-digit characters\n",
    "customers['phone_clean'] = customers['phone'].str.replace(r'\\D', '', regex=True)\n",
    "print(f\"Digits only: {customers['phone_clean'].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f686054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format phone numbers consistently\n",
    "def format_phone(phone):\n",
    "    \"\"\"\n",
    "    Format phone number as (XXX) XXX-XXXX\n",
    "    \"\"\"\n",
    "    if pd.isna(phone):\n",
    "        return np.nan\n",
    "    \n",
    "    # Remove all non-digits\n",
    "    digits = re.sub(r'\\D', '', str(phone))\n",
    "    \n",
    "    # Handle international prefix\n",
    "    if len(digits) == 11 and digits[0] == '1':\n",
    "        digits = digits[1:]\n",
    "    \n",
    "    # Format if we have 10 digits\n",
    "    if len(digits) == 10:\n",
    "        return f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n",
    "    else:\n",
    "        return phone  # Return original if can't format\n",
    "\n",
    "customers['phone_formatted'] = customers['phone'].apply(format_phone)\n",
    "print(\"=== Formatted Phone Numbers ===\")\n",
    "print(customers[['phone', 'phone_formatted']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a942d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple replacements with a dictionary\n",
    "abbreviations = {\n",
    "    'St': 'Street',\n",
    "    'Ave': 'Avenue',\n",
    "    'Rd': 'Road',\n",
    "    'Blvd': 'Boulevard',\n",
    "    'Dr': 'Drive'\n",
    "}\n",
    "\n",
    "# Create pattern from dictionary\n",
    "def expand_abbreviations(text, mapping):\n",
    "    for abbrev, full in mapping.items():\n",
    "        # Use word boundaries to avoid partial replacements\n",
    "        text = re.sub(rf'\\b{abbrev}\\b', full, text)\n",
    "    return text\n",
    "\n",
    "customers['address_expanded'] = customers['address'].apply(\n",
    "    lambda x: expand_abbreviations(x, abbreviations)\n",
    ")\n",
    "\n",
    "print(\"=== Expanded Abbreviations ===\")\n",
    "print(customers[['address', 'address_expanded']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22573347",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Regular Expressions (Regex) for Data Analysts\n",
    "\n",
    "Regex is powerful for pattern matching. Here are the most useful patterns for data cleaning.\n",
    "\n",
    "### Essential Regex Patterns\n",
    "\n",
    "| Pattern | Description | Example Match |\n",
    "|---------|-------------|---------------|\n",
    "| `\\d` | Any digit | 0, 1, 2, ... |\n",
    "| `\\D` | Any non-digit | a, @, ! |\n",
    "| `\\w` | Word character (letter, digit, _) | a, 1, _ |\n",
    "| `\\W` | Non-word character | @, !, space |\n",
    "| `\\s` | Whitespace | space, tab, newline |\n",
    "| `+` | One or more | `\\d+` matches \"123\" |\n",
    "| `*` | Zero or more | `\\d*` matches \"\" or \"123\" |\n",
    "| `?` | Zero or one | `colou?r` matches \"color\" or \"colour\" |\n",
    "| `{n}` | Exactly n times | `\\d{4}` matches \"2024\" |\n",
    "| `{n,m}` | Between n and m times | `\\d{2,4}` matches \"12\" to \"1234\" |\n",
    "| `^` | Start of string | `^Hello` |\n",
    "| `$` | End of string | `world$` |\n",
    "| `\\b` | Word boundary | `\\bcat\\b` matches \"cat\" not \"category\" |\n",
    "| `( )` | Capture group | `(\\d{3})` captures 3 digits |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b20b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data with various patterns\n",
    "data = pd.DataFrame({\n",
    "    'text': [\n",
    "        'Order #12345 placed on 2024-01-15',\n",
    "        'Invoice INV-2024-0001 total $1,234.56',\n",
    "        'Customer ID: CUST-789, Email: john@example.com',\n",
    "        'SKU: ABC-123-XYZ, Qty: 5',\n",
    "        'Phone: (555) 123-4567, Fax: 555-987-6543'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Sample text data:\")\n",
    "for i, text in enumerate(data['text']):\n",
    "    print(f\"{i}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patterns using .str.extract()\n",
    "print(\"=== Extract Patterns ===\")\n",
    "\n",
    "# Extract order numbers (# followed by digits)\n",
    "data['order_num'] = data['text'].str.extract(r'#(\\d+)')\n",
    "\n",
    "# Extract dates (YYYY-MM-DD format)\n",
    "data['date'] = data['text'].str.extract(r'(\\d{4}-\\d{2}-\\d{2})')\n",
    "\n",
    "# Extract dollar amounts\n",
    "data['amount'] = data['text'].str.extract(r'\\$([\\d,]+\\.?\\d*)')\n",
    "\n",
    "# Extract email addresses\n",
    "data['email'] = data['text'].str.extract(r'([\\w.]+@[\\w.]+)')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3888a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract multiple groups\n",
    "print(\"=== Extract Multiple Groups ===\")\n",
    "\n",
    "# Extract all phone numbers\n",
    "phone_pattern = r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}'\n",
    "data['phones'] = data['text'].str.findall(phone_pattern)\n",
    "print(data[['text', 'phones']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b1244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if pattern exists using .str.contains()\n",
    "print(\"=== Pattern Matching ===\")\n",
    "\n",
    "# Contains email address?\n",
    "data['has_email'] = data['text'].str.contains(r'[\\w.]+@[\\w.]+', regex=True)\n",
    "\n",
    "# Contains money amount?\n",
    "data['has_amount'] = data['text'].str.contains(r'\\$[\\d,]+', regex=True)\n",
    "\n",
    "print(data[['text', 'has_email', 'has_amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3a4b4d",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Common Text Cleaning Tasks\n",
    "\n",
    "### 5.1 Standardizing Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messy names from different sources\n",
    "names = pd.DataFrame({\n",
    "    'raw_name': [\n",
    "        '  SMITH, JOHN  ',\n",
    "        'jane doe',\n",
    "        'Dr. Robert Johnson III',\n",
    "        'O\\'Connor, Mary',\n",
    "        'jean-pierre DUPONT',\n",
    "        'van der Berg, Peter',\n",
    "        'WILLIAMS,   SARAH'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Original names:\")\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    \"\"\"\n",
    "    Clean and standardize a name.\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return np.nan\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    name = ' '.join(name.split())\n",
    "    \n",
    "    # Handle \"LAST, FIRST\" format\n",
    "    if ',' in name:\n",
    "        parts = name.split(',')\n",
    "        if len(parts) == 2:\n",
    "            name = f\"{parts[1].strip()} {parts[0].strip()}\"\n",
    "    \n",
    "    # Title case (but preserve lowercase particles like 'van', 'de', 'der')\n",
    "    particles = ['van', 'de', 'der', 'von', 'la', 'le']\n",
    "    words = name.lower().split()\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if word in particles and result:  # Only keep lowercase if not first word\n",
    "            result.append(word)\n",
    "        else:\n",
    "            result.append(word.capitalize())\n",
    "    \n",
    "    return ' '.join(result)\n",
    "\n",
    "names['clean_name'] = names['raw_name'].apply(clean_name)\n",
    "print(\"\\nCleaned names:\")\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de6ad9",
   "metadata": {},
   "source": [
    "### 5.2 Validating Email Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email validation\n",
    "emails = pd.DataFrame({\n",
    "    'email': [\n",
    "        'john@example.com',\n",
    "        'Jane.Doe@company.co.uk',\n",
    "        'invalid-email',\n",
    "        'test@test',\n",
    "        'user.name+tag@domain.org',\n",
    "        '@nodomain.com',\n",
    "        'noat.com'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Basic email pattern\n",
    "email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "\n",
    "emails['is_valid'] = emails['email'].str.match(email_pattern)\n",
    "emails['email_lower'] = emails['email'].str.lower()\n",
    "\n",
    "print(\"Email Validation:\")\n",
    "print(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf8166",
   "metadata": {},
   "source": [
    "### 5.3 Cleaning Product Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830223f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messy product data\n",
    "products = pd.DataFrame({\n",
    "    'description': [\n",
    "        'iPhone 13 Pro  - 128GB   Blue',\n",
    "        'SAMSUNG Galaxy S21, 256gb, BLACK',\n",
    "        'google pixel 6 -- 128 gb (white)',\n",
    "        'OnePlus 9 Pro\\n256GB\\nGreen',\n",
    "        'Sony   Xperia   5   III    128GB'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Original descriptions:\")\n",
    "print(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154bc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_product_description(desc):\n",
    "    \"\"\"\n",
    "    Standardize product descriptions.\n",
    "    \"\"\"\n",
    "    if pd.isna(desc):\n",
    "        return np.nan\n",
    "    \n",
    "    # Replace newlines and tabs with spaces\n",
    "    desc = re.sub(r'[\\n\\t\\r]', ' ', desc)\n",
    "    \n",
    "    # Remove multiple dashes\n",
    "    desc = re.sub(r'-+', '-', desc)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    desc = re.sub(r'\\s+', ' ', desc)\n",
    "    \n",
    "    # Standardize storage format (128gb -> 128GB)\n",
    "    desc = re.sub(r'(\\d+)\\s*gb', r'\\1GB', desc, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove parentheses\n",
    "    desc = re.sub(r'[\\(\\)]', '', desc)\n",
    "    \n",
    "    # Remove leading/trailing whitespace and punctuation\n",
    "    desc = desc.strip(' -,')\n",
    "    \n",
    "    return desc\n",
    "\n",
    "products['clean_description'] = products['description'].apply(clean_product_description)\n",
    "print(\"\\nCleaned descriptions:\")\n",
    "print(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a22567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract product attributes\n",
    "products['brand'] = products['clean_description'].str.extract(r'^([\\w]+)')\n",
    "products['storage'] = products['clean_description'].str.extract(r'(\\d+GB)')\n",
    "products['color'] = products['clean_description'].str.extract(r'(Blue|Black|White|Green|Red)', \n",
    "                                                               flags=re.IGNORECASE)\n",
    "products['color'] = products['color'].str.title()\n",
    "\n",
    "print(\"\\nExtracted attributes:\")\n",
    "print(products[['clean_description', 'brand', 'storage', 'color']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24253f6",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Handling Special Characters and Encoding\n",
    "\n",
    "International data often has special characters that need attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49225d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# International names and text\n",
    "international = pd.DataFrame({\n",
    "    'name': ['José García', 'François Müller', 'Søren Østergaard', \n",
    "             'Владимир', 'محمد', '田中太郎'],\n",
    "    'city': ['São Paulo', 'Zürich', 'København', 'Москва', 'الرياض', '東京']\n",
    "})\n",
    "\n",
    "print(\"International data:\")\n",
    "print(international)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0793a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove accents for ASCII-only systems\n",
    "import unicodedata\n",
    "\n",
    "def remove_accents(text):\n",
    "    \"\"\"\n",
    "    Remove accents from text while preserving base letters.\n",
    "    Only works for Latin-based scripts.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    \n",
    "    # Normalize unicode and remove accents\n",
    "    normalized = unicodedata.normalize('NFKD', text)\n",
    "    ascii_text = normalized.encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    return ascii_text if ascii_text else text  # Return original if result is empty\n",
    "\n",
    "international['name_ascii'] = international['name'].apply(remove_accents)\n",
    "international['city_ascii'] = international['city'].apply(remove_accents)\n",
    "\n",
    "print(\"\\nWith ASCII versions:\")\n",
    "print(international)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe5ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect script type\n",
    "def detect_script(text):\n",
    "    \"\"\"\n",
    "    Detect the primary script used in text.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or len(text) == 0:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Count characters by script\n",
    "    scripts = {'Latin': 0, 'Cyrillic': 0, 'Arabic': 0, 'CJK': 0}\n",
    "    \n",
    "    for char in text:\n",
    "        if '\\u0000' <= char <= '\\u007F' or '\\u00C0' <= char <= '\\u024F':\n",
    "            scripts['Latin'] += 1\n",
    "        elif '\\u0400' <= char <= '\\u04FF':\n",
    "            scripts['Cyrillic'] += 1\n",
    "        elif '\\u0600' <= char <= '\\u06FF':\n",
    "            scripts['Arabic'] += 1\n",
    "        elif '\\u4E00' <= char <= '\\u9FFF' or '\\u3040' <= char <= '\\u30FF':\n",
    "            scripts['CJK'] += 1\n",
    "    \n",
    "    # Return the most common script\n",
    "    return max(scripts, key=scripts.get) if max(scripts.values()) > 0 else 'Unknown'\n",
    "\n",
    "international['name_script'] = international['name'].apply(detect_script)\n",
    "print(\"\\nScript detection:\")\n",
    "print(international[['name', 'name_script']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010f371",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Practical Exercises\n",
    "\n",
    "### Exercise 1: Clean Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a950563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messy customer data\n",
    "messy_customers = pd.DataFrame({\n",
    "    'full_name': ['  JOHNSON, MARY  ', 'Robert Smith Jr.', '  sarah   o\\'brien  ',\n",
    "                  'Dr. James WILSON', 'emily-rose davis'],\n",
    "    'email': ['MARY.J@Gmail.COM', 'r.smith@@company.com', 'sarah.o.brien@outlook',\n",
    "              'jwilson@hospital.org', 'Emily_Davis@yahoo.com'],\n",
    "    'phone': ['555.123.4567', '(555) 234-5678', '555-345-6789',\n",
    "              '15554567890', '+1 (555) 567-8901']\n",
    "})\n",
    "\n",
    "print(\"Messy customer data:\")\n",
    "print(messy_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f7546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean the customer data\n",
    "# 1. Standardize names (Title Case, handle \"LAST, FIRST\" format)\n",
    "# 2. Split into first_name and last_name\n",
    "# 3. Clean and validate email addresses (lowercase, mark invalid ones)\n",
    "# 4. Standardize phone numbers to (XXX) XXX-XXXX format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de68b9",
   "metadata": {},
   "source": [
    "### Exercise 2: Extract Information from Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c847c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log data\n",
    "logs = pd.DataFrame({\n",
    "    'log_entry': [\n",
    "        '[2024-01-15 10:23:45] ERROR: Failed to connect to 192.168.1.100:8080',\n",
    "        '[2024-01-15 10:24:12] INFO: User admin logged in from IP 10.0.0.5',\n",
    "        '[2024-01-15 10:25:33] WARNING: Disk usage at 85% on server-01',\n",
    "        '[2024-01-15 10:26:01] ERROR: Database timeout after 30s',\n",
    "        '[2024-01-15 10:27:45] INFO: Backup completed successfully, size: 2.5GB'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Log entries:\")\n",
    "for log in logs['log_entry']:\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract the following from each log entry:\n",
    "# 1. timestamp (convert to datetime)\n",
    "# 2. log_level (ERROR, INFO, WARNING)\n",
    "# 3. ip_address (if present)\n",
    "# 4. message (everything after the log level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7ecbe",
   "metadata": {},
   "source": [
    "### Exercise 3: Clean Survey Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5948793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survey responses with free text\n",
    "survey = pd.DataFrame({\n",
    "    'response': [\n",
    "        'I REALLY loved the product!!!',\n",
    "        '  meh... it was ok i guess   ',\n",
    "        'TERRIBLE customer service!!!! Never again!!!',\n",
    "        'Great product, fast shipping :)',\n",
    "        'wtf is this garbage???',\n",
    "        'Pretty good. Would recommend.',\n",
    "        'N/A',\n",
    "        ''\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Survey responses:\")\n",
    "print(survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c00aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean the survey data\n",
    "# 1. Handle empty/N/A responses\n",
    "# 2. Normalize case (Title Case or lowercase)\n",
    "# 3. Remove excessive punctuation (multiple !, ?, etc.)\n",
    "# 4. Calculate word count\n",
    "# 5. Add a 'has_profanity' flag (for words like 'wtf', 'garbage')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e455564",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Key Takeaways\n",
    "\n",
    "### ✅ Essential `.str` Methods\n",
    "\n",
    "```python\n",
    "# Case conversion\n",
    "df['col'].str.lower() / .str.upper() / .str.title()\n",
    "\n",
    "# Whitespace\n",
    "df['col'].str.strip() / .str.lstrip() / .str.rstrip()\n",
    "\n",
    "# Split and join\n",
    "df['col'].str.split('delimiter', expand=True)\n",
    "df['col'].str.cat(df['col2'], sep=' ')\n",
    "\n",
    "# Search and replace\n",
    "df['col'].str.contains('pattern', regex=True)\n",
    "df['col'].str.replace('old', 'new', regex=True)\n",
    "df['col'].str.extract(r'(pattern)')\n",
    "\n",
    "# Length and slicing\n",
    "df['col'].str.len()\n",
    "df['col'].str[0:5]\n",
    "```\n",
    "\n",
    "### ✅ Common Regex Patterns\n",
    "\n",
    "```python\n",
    "# Email: r'^[\\w.+-]+@[\\w.-]+\\.[a-zA-Z]{2,}$'\n",
    "# Phone: r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}'\n",
    "# Date: r'\\d{4}-\\d{2}-\\d{2}'\n",
    "# Money: r'\\$[\\d,]+\\.?\\d*'\n",
    "# Digits only: r'\\d+'\n",
    "# Non-digits: r'\\D'\n",
    "```\n",
    "\n",
    "### ⚠️ Common Mistakes\n",
    "\n",
    "1. Forgetting `regex=True` when using patterns\n",
    "2. Not handling NaN values before string operations\n",
    "3. Case sensitivity issues (always `.str.lower()` before comparing)\n",
    "4. Not escaping special regex characters (`$`, `.`, `?`, etc.)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
